{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import gc\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(2019)\n",
    "random.seed(2019)\n",
    "pd.set_option('display.max_rows', 20)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 280)\n",
    "pd.set_option('display.max_colwidth', 150)\n",
    "data_path = '/data/workspace/kimi/tencent_ads/2020/dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         user_id  active_days  click_times_total  age  gender  industry_0  industry_1  industry_2  industry_3  industry_4  industry_5  industry_6  industry_7  industry_8  industry_9  industry_10  industry_11  industry_12  industry_13  industry_14  industry_15  advertiser_id_0  \\\n",
      "0            1.0         10.0               14.0  3.0     0.0   -9.808951   37.956196    7.941766   28.995136   58.130238   11.259385    5.808714  -13.792348   33.056450   26.614384     3.608611    36.279411    29.554661    -2.248151    21.378246    -2.297685        19.044678   \n",
      "1            2.0         28.0               46.0  9.0     0.0 -128.622192 -112.712936    0.871585  215.566101  110.969002  -68.562981  -11.905766  144.337372   75.368713   49.570419   -88.037415   180.578781    18.416990     1.990750    39.252247   -67.675323        33.550327   \n",
      "2            3.0         23.0               30.0  6.0     1.0   29.386518   -1.617431  -70.038635   90.258026  -76.959198  131.956375   -9.560961  -42.434490   -8.002237   83.510330    43.811249    91.752304   -25.199110   -73.903412    60.602314    22.645639        31.653465   \n",
      "3            4.0         15.0               29.0  4.0     0.0  -16.686899  -25.686497  -24.952703   91.247353   14.408211    4.188763    3.343855   40.266094   29.248093   54.475338    56.646095   188.203674    -4.883315   -54.998981   107.132889    76.683212         7.386368   \n",
      "4            5.0         26.0               34.0  3.0     0.0    5.791319  -67.389877   -8.146427   35.269707  -19.237253   57.649216   26.431267  -28.947592    2.966151   47.215485    10.524098    29.089153    31.284756    28.660940    -8.921389    -0.230173        21.522133   \n",
      "5            6.0         14.0               17.0  5.0     0.0  -47.572433   33.222157   15.830864   -8.697951  -50.758102  -28.726913   19.976673  -28.017670  -40.738800   -2.100759   -28.024986   -30.171013   -25.395550    -5.817398    13.383845     9.226968         6.174144   \n",
      "6            7.0         10.0               10.0  5.0     1.0  -15.115604    3.081500    7.368120    3.015714    3.811103   16.733843    9.414579    6.466442   -0.142935   14.569681    -7.331502    -4.972031   -15.000908     1.476685    -8.231017     7.219330         4.746326   \n",
      "7            8.0         34.0               52.0  4.0     0.0  -91.646973  -97.774872  -35.305008   91.926483   61.369476  -58.951984   46.314659   38.782688   14.432944   32.982033    63.801743    80.614067   131.728577    27.473368    37.105118   -38.851254        -1.705563   \n",
      "8            9.0         17.0               21.0  4.0     0.0  -79.317268   73.184219  -53.498680   64.025513  133.581970  -36.565769   40.288570  -42.299671   54.129177   78.508896    23.259687    57.915718    70.186577    28.408512    26.904936   -73.159531       -38.093884   \n",
      "9           10.0         10.0               10.0  8.0     1.0    9.411184   16.930286   -4.892458  -19.217512    9.090284   -5.744177  -26.759222   30.227558   -4.855068   -2.336195   -35.584946   -21.417782    20.975512     5.329531    51.917473    28.345232        -3.910127   \n",
      "...          ...          ...                ...  ...     ...         ...         ...         ...         ...         ...         ...         ...         ...         ...         ...          ...          ...          ...          ...          ...          ...              ...   \n",
      "899990  899991.0         68.0              153.0  2.0     0.0  326.555847  135.785446   27.702246 -272.836853 -391.483978 -468.331787 -563.931641 -273.459290 -220.778046   24.328651   218.521957  -104.100334   -52.643139   282.605194   147.629364   131.873474        92.013550   \n",
      "899991  899992.0         23.0               37.0  8.0     0.0  -97.034714   45.442123   21.807625   63.256271   11.867814  -39.235126   44.469296  -79.595024  -67.714645   70.193069   -80.420319    24.029633    -4.943937    56.105637     7.923001    -5.819687       -23.890692   \n",
      "899992  899993.0         30.0               47.0  1.0     1.0  -11.175653 -118.207542   12.250732  172.121704  -17.693842   61.753738   19.896235   49.060181   50.631222   -1.883620    83.158470    73.320633   159.354599   -70.671791    33.345913  -110.670471        81.261406   \n",
      "899993  899994.0         11.0               14.0  3.0     1.0   -3.821590  -25.679916    0.287683   16.271614   16.837450   23.094139  -17.272753   -5.162896  -10.694007   18.355431   -17.942696    32.582611   -17.666100   -10.662220    19.131662   -20.940222       -11.878759   \n",
      "899994  899995.0         16.0               20.0  1.0     1.0    8.795276   -9.550294   24.917002  -36.244534   13.716184  -30.974894  -27.244205  -28.139681   14.607081  -24.148455   -33.011169     2.864487    36.914738    48.314892    49.496941    20.686798        -3.328820   \n",
      "899995  899996.0         12.0               14.0  4.0     0.0  -68.339561   16.089041   29.436728   27.052691  -97.190880  -31.615200   -4.235044  -46.817146  -46.990112   32.091629   -28.340277   -56.207031   -61.132935   -12.178814   -19.564672     5.943604        -5.487632   \n",
      "899996  899997.0         14.0               20.0  2.0     1.0  -37.928074  -49.610336  -17.000492    0.709101   70.140137   -6.983108  -74.425499   39.929226   12.805101  -39.762329   -57.969822    13.739494    12.516728     3.560076    20.042730    40.879559        11.134377   \n",
      "899997  899998.0         10.0               15.0  3.0     1.0    3.217826    3.344387   24.457531   14.533845  -11.576995   18.707205   10.781302  -28.982231   -7.170389   16.912634    -4.656260    50.753288    12.412258    14.246692    64.103477    32.206505        -5.464124   \n",
      "899998  899999.0         17.0               22.0  2.0     0.0  -34.773178   16.068611   16.649147   26.549845   49.258930    2.891699  -10.940468  -19.095585   -1.256871   35.790844   -13.388332    31.776043    15.391781     3.195548    18.583775    61.004974        20.992483   \n",
      "899999  900000.0         12.0               12.0  2.0     1.0   13.834448    3.321691   18.036522  -42.859570   16.049595    2.205222   11.756025  -49.220108  -10.939990    9.273026     9.913195   -14.234210    38.738365    36.006489     7.470430    40.632980        10.781995   \n",
      "\n",
      "        advertiser_id_1  advertiser_id_2  advertiser_id_3  advertiser_id_4  advertiser_id_5  advertiser_id_6  advertiser_id_7  advertiser_id_8  advertiser_id_9  advertiser_id_10  advertiser_id_11  advertiser_id_12  advertiser_id_13  advertiser_id_14  advertiser_id_15  \\\n",
      "0              2.646738       -10.923330         8.316883       -15.192047         6.235408         7.005152        -9.548692        -6.332948        -5.346463         10.010803          7.865358         10.131121         -4.466543          9.082926         -7.336315   \n",
      "1            -28.297802        18.040586        -6.568824        35.452190        16.826866       -16.439434       -25.614212        44.163635         6.848547        -16.363033         59.262661         34.614597         14.276314         31.357521        -81.232674   \n",
      "2             -8.096686       -10.086653       -11.883622       -12.388768       -20.975471        26.095974        21.539877        25.817772        11.871653        -22.179882         -0.051191         18.239691         -4.340840        -11.120042        -10.542468   \n",
      "3            -27.251160       -19.657225        -1.263146         6.284375       -12.919456        12.555063        14.392303        17.608242        21.212177          5.445278          2.710409          6.952283        -12.278353        -12.572432        -61.014694   \n",
      "4             15.376991        32.476833       -17.688856        27.724825        28.077034        22.395422         0.405544         7.703856        25.271608         25.511307         35.667892        -23.849613         15.613408         24.350346          6.430612   \n",
      "5             -7.938291        20.649220         4.449851        -8.360475       -18.837267        37.294128        28.075895       -34.756546         4.701242        -11.383329        -11.166034          2.409151          3.556219          6.818281          0.867387   \n",
      "6              0.547726        -1.579669        -5.614305         0.213028        -3.476271        10.323250        -8.247450        -2.537269        -2.560976         -8.976208         -6.298287          0.086275          7.836846          2.425070         -5.462629   \n",
      "7            -51.396458       -23.152731        33.983669        16.695770        -0.217516        13.642845       -19.291157        -1.265625         7.462703          5.278865          4.026690         -1.102639          0.332900          2.117147        -33.990044   \n",
      "8            -22.709747        -6.353973         8.246285        16.572643        -2.026333         6.335961       -10.859792        -9.330000        15.160890         -8.894979         20.768307          9.484232         20.034296         -6.149426          0.583545   \n",
      "9            -12.720874       -12.571702        11.762899       -11.259969        14.758829        -2.604074       -14.380464        -4.094647         4.648204          7.814003          3.660595         15.129541        -10.157825          4.438422         -8.428732   \n",
      "...                 ...              ...              ...              ...              ...              ...              ...              ...              ...               ...               ...               ...               ...               ...               ...   \n",
      "899990        33.017372      -124.899216       313.428223      -236.804123       263.095428        95.854912      -103.543030      -256.728546       166.640839        282.424377        -37.522144        264.585388       -306.831329        184.610840         12.175954   \n",
      "899991        11.057524       -59.915546       -37.784599        -8.578413         5.359051        80.700089       -10.370084         3.939857       -46.229492        -15.186784        -18.846125         -2.395460         41.677830         32.778782         23.204153   \n",
      "899992       -55.242760        20.971552       -21.211006        22.427469         3.795413         0.484938       -20.029911        52.038509         0.531621          8.403048          5.603034         49.516617         21.797066         16.118708        -24.646982   \n",
      "899993        -5.910614       -14.665703        10.069134        17.963966         8.190911        -4.825675        12.503391        14.490153        -6.259642         28.004387         34.453289         -0.923202        -18.031162         -1.173379        -38.048256   \n",
      "899994         8.056237       -45.148335        19.577841       -31.067268        22.401712         0.444232        -3.067173       -17.622004         6.175544         61.038387         -1.622181         55.688522        -41.850670          0.937162        -16.432184   \n",
      "899995         3.758287        16.018873       -14.858812        -7.380956       -18.172409        57.085056        -5.409493       -15.022413       -12.304090         -7.208265         16.007587          3.638813         16.380585         21.205452        -25.808926   \n",
      "899996         3.601202       -25.394682         0.868693         3.708371        19.587883         3.810929       -20.836615        27.561745        -6.588935         11.179300          2.665829         22.247635         15.720448         15.148580        -14.849353   \n",
      "899997        -3.123843       -33.192402        12.392257       -16.817696         9.180411        18.691889         8.498488       -10.584435        -7.250376         30.946375          1.300171         21.485453        -29.931765        -13.901173        -12.555669   \n",
      "899998        -1.291168       -28.949575         9.052095       -13.532509         4.973066         3.427888       -22.298788       -26.080090        25.091995         15.933252         -7.835224         21.920084         14.737563         34.957378        -28.659443   \n",
      "899999         5.192842       -15.155756         7.755407       -17.763409         3.329348        12.154191        -3.151804       -15.236206         1.950399         11.245798         -7.811395         22.385460        -16.387585          5.830271         -5.852991   \n",
      "\n",
      "        advertiser_id_16  advertiser_id_17  advertiser_id_18  advertiser_id_19  advertiser_id_20  advertiser_id_21  advertiser_id_22  advertiser_id_23  advertiser_id_24  advertiser_id_25  advertiser_id_26  advertiser_id_27  advertiser_id_28  advertiser_id_29  advertiser_id_30  \\\n",
      "0              -6.341317        -18.436115         -8.178473         -0.119107         -1.945745         22.225527        -14.013163        -13.331675         -7.004823         -2.965183         -1.858813         18.093512         22.943226          5.667455         -5.222592   \n",
      "1              50.724895        -36.948727         15.434275       -109.077904        -35.761948         40.848099        -19.099123       -127.340416          0.374289        -15.034623        -25.103188        104.370949         57.913887         15.150474         11.199646   \n",
      "2               8.472021        -10.691156         -1.005903         20.733109          2.884441          3.674151         48.526733          9.739180        -20.209114        -25.772644         12.191095         13.855778         32.792156          8.469959        -23.665455   \n",
      "3              20.602262        -61.725414        -14.317286        -32.900963        -32.059669         38.052002        -18.772488        -43.633335         -4.342166         -3.456164         -9.750835         28.940933         16.873575         16.948990        -12.934023   \n",
      "4               5.660636         -4.252624         -9.505592         -8.873924         24.276571         33.812008        -52.697594        -13.802563         11.145633         -3.600050          3.914080        -18.224915         39.847176        -10.092799        -16.461929   \n",
      "5              -7.373596         -0.358308          8.000278         15.132558         -1.293578         27.479818         -9.567595        -11.375083         12.440532         31.647223         -2.790546        -11.490863         12.448193         -3.574531        -30.983311   \n",
      "6              -5.598744         -5.590835         -5.944918          1.305913         -2.604759         -0.005327         -3.204876         -0.151060         -1.687717          3.300213         10.931580         -0.130375         14.898123          5.481349          4.040372   \n",
      "7              20.303785        -77.330322          0.733843        -47.093082        -26.536219         91.183296        -33.001514        -26.730322        -51.982346        -16.614199        -60.280754        100.375404         54.662155         37.601257        -64.803505   \n",
      "8              13.945364        -24.511173         -1.983613          7.758264          0.559086         12.191262         -4.402057        -22.206375        -26.982456         -3.907485        -14.339113         65.167709          7.919713         -1.359399        -10.479012   \n",
      "9              14.689396         -3.640149         -4.719844          2.488721        -10.039789         30.147463         -4.616349         -4.188347          9.469654          5.881608          7.960936          8.320744         26.964544          1.415648          0.609357   \n",
      "...                  ...               ...               ...               ...               ...               ...               ...               ...               ...               ...               ...               ...               ...               ...               ...   \n",
      "899990         10.487251       -181.104141       -135.719482         65.410767         22.626442        427.102570         -5.323522        -61.133167          5.442577        217.764236         48.958511        114.628754        289.661346         93.542435        -43.429871   \n",
      "899991         33.174946        -21.583548         63.586903        -24.973398         24.169743         -1.894974         13.020576        -76.686134        -37.146980          8.232638        -39.147995         46.903255         46.032265        -28.438843        -32.346901   \n",
      "899992        -20.025454        -56.775414          0.767968        -31.644499        -44.577606         20.647079          0.166292          9.845706        -18.872440        -71.634933         31.751183          4.714602         36.763744         40.186665        -20.712734   \n",
      "899993         14.635303        -16.961109         -9.697069        -22.403006        -13.042419         34.963848         -1.695170        -11.732201        -11.954227         -3.464150         -8.012836         14.064403         20.472946         -8.165325         -8.706247   \n",
      "899994         22.545460        -38.727966        -23.849419          0.185866        -10.557862         73.016312          5.640604        -11.625959         23.359432         35.553082          5.964092         48.882210         55.059361         -0.755334        -25.779800   \n",
      "899995        -16.871250          1.055410          9.556680          9.774263         -2.014333         12.637768         -9.151257         -8.377117          0.204338          2.428854        -23.507952        -13.088191         -0.346231         18.032084         -2.315709   \n",
      "899996         37.839336          3.906561        -20.177599          4.878056        -14.796834         31.469366         -8.365758        -16.141533         18.059244          9.831993          4.246104         -1.843312         46.958122         19.259270         -0.406521   \n",
      "899997         20.209085        -26.242188        -10.139357         -3.266544          0.630338         37.548958         18.051752        -11.685170          9.791186         10.533558         -2.477855         39.212967         25.478304         -2.687893        -15.810619   \n",
      "899998         15.390471        -26.640013        -31.680859         22.469086          5.822981         47.966244        -29.223196        -18.110010          5.316890         30.613537         21.592514         11.367332         12.658487         -0.856222         -6.653316   \n",
      "899999          2.377951        -18.439943          1.219978          4.488073          1.197315         25.752634         -7.414225         -2.786758          1.256809          8.871619         14.132691          5.941120         16.174938          1.749919        -17.425980   \n",
      "\n",
      "        advertiser_id_31  advertiser_id_32  advertiser_id_33  advertiser_id_34  advertiser_id_35  advertiser_id_36  advertiser_id_37  advertiser_id_38  advertiser_id_39  advertiser_id_40  advertiser_id_41  advertiser_id_42  advertiser_id_43  advertiser_id_44  advertiser_id_45  \\\n",
      "0              -3.355712          9.752412        -13.316645          7.804801         24.305037         14.514184         -3.366591          5.188654          4.717665         -0.859411         17.232815         -5.000290         20.952806         16.674566         -2.308511   \n",
      "1             -50.098087         25.288809         -4.529882          8.920462        -24.764839        -41.944729         26.121130         24.831484        130.765579        -67.729523         50.743248         64.277374        -12.822583         10.522196        -84.542130   \n",
      "2               9.618413         15.108822          9.268209         61.967205         40.592495        -18.176823        -42.359436        -15.399177        -30.124918          0.266373         21.603262         44.309116          1.898752         -1.072294         16.869234   \n",
      "3              -3.956140          0.283003          7.878389         -0.490339         21.695786         -3.514889         15.733627        -17.984938         49.144547         -3.087263         12.047553         57.282459         23.763855         24.009501         -0.831132   \n",
      "4             -52.498508         44.153561        -21.565018         15.464695         52.286106         14.792874         -0.385313         23.215822        -40.831055         -5.114897         -0.120986         26.785593         26.949133         22.828987        -10.433783   \n",
      "5              -0.608121         10.954537         44.486267         12.539992         -0.671526         -8.235823        -13.334953         -3.235057        -25.775246         15.184714         50.540604         -0.883600         16.012970         33.420517          5.072310   \n",
      "6               1.593889         -2.240838         -8.298329          6.753617          4.226621         -2.376707         -3.519867          6.180136         -6.518219         -1.532597          4.608341          8.528646         -3.191524          8.984652         -1.601495   \n",
      "7               1.315459        -34.400665         34.578903         32.543770        -23.365631        -22.289597          2.056538        -18.040623         66.552498        -32.360992          6.405365         30.852940         41.008427         23.872263        -15.247359   \n",
      "8              -5.643446          9.761158         11.878071         56.503162        -36.558777        -16.007521         -0.665831         10.327637         45.314705        -25.133472         24.994026         21.398722         -3.316730         20.210848        -23.882729   \n",
      "9               0.624398         -8.790364          0.249472         -9.982694          8.191742        -12.603639          7.229002         -1.964982          0.540725         -5.811424         18.350567         -6.911809         23.238281         19.606749         -6.953174   \n",
      "...                  ...               ...               ...               ...               ...               ...               ...               ...               ...               ...               ...               ...               ...               ...               ...   \n",
      "899990        120.771500       -117.543343       -167.666016        -95.460701         20.924168       -158.121277          6.009544       -148.910553        105.835228       -163.885696        286.795044       -315.989288        328.213531        228.571564         39.511574   \n",
      "899991          8.519527          3.140433         -8.683735        -15.938507         -7.767870          5.426641        -11.267524         12.694574        -11.629957        -37.658615         34.587410         33.072975         15.710884         13.024841         17.140612   \n",
      "899992         16.610008         -1.892624          5.158397         59.502487          5.435385          6.746637        -38.742088        -18.907499          5.819019        -16.930681         20.443808         59.013657         44.782696        -13.023861        -41.459534   \n",
      "899993          8.476070          1.170329         -8.532707         14.386730        -10.481611        -28.540817          3.996452         -6.896755         45.460060         -9.676764         23.171341         12.977412         25.060820          3.182298          4.118804   \n",
      "899994         30.098101        -32.083912        -29.789236        -11.687021          3.311484        -41.312824         15.506455        -30.373974         68.242714        -19.589960         57.077335        -25.979177         44.402790         42.515434         17.453856   \n",
      "899995         -0.360130         27.519810          0.851839         -3.562751          5.263657        -17.763111         -2.848173         30.668655        -21.191643         -6.368656          9.973385         11.499262         29.820541        -16.492277          2.825501   \n",
      "899996        -21.230923        -19.360653         -6.912618          2.006109         13.302731        -33.812832         14.684354          6.683860         23.687328         -3.998722         36.391163         26.630100         20.443754         24.208118         -0.874610   \n",
      "899997         20.777124        -14.073114        -16.838444          3.381408         -2.819007        -18.303825          3.658323        -23.783579         30.198048         -0.026045         30.240555         -3.622831         25.907789         26.575872         22.161228   \n",
      "899998        -23.461046         13.397810        -32.126293          9.774704         43.581005        -22.709915         34.219761          3.929787         19.915607        -22.135923         54.001331          2.920850         40.011757         35.910103          3.261245   \n",
      "899999         -6.658821         -5.062423        -12.785007         -1.396456         18.442167          0.686548         16.030699         -4.064944          2.112015        -15.442138         26.995989        -10.844050         16.352846         16.055634          8.197340   \n",
      "\n",
      "        advertiser_id_46  advertiser_id_47  advertiser_id_48  advertiser_id_49  advertiser_id_50  advertiser_id_51  advertiser_id_52  advertiser_id_53  advertiser_id_54  advertiser_id_55  advertiser_id_56  advertiser_id_57  advertiser_id_58  advertiser_id_59  advertiser_id_60  \\\n",
      "0              -9.373766         -0.663107         -0.370034         -3.570216          2.593892          6.375855        -15.623655          1.824960        -19.110241          6.800398        -10.365419          4.891439          0.133713         -9.298365         -4.488817   \n",
      "1             -20.848557         38.990124         19.784224         -0.102614        -21.977848        -61.018078         26.289015       -101.331352        -87.446503         18.774628         -8.235213         29.826511        -12.054276        -29.679073          1.603220   \n",
      "2             -15.156662        -18.013103        -10.041327        -29.299793        -39.020763         -4.266019          1.639847        -28.736040         26.305037         -6.380790         11.106070         -3.441447         -5.715797          7.599668        -23.605350   \n",
      "3             -37.973957         15.487065         -2.945199        -18.096041        -19.639269        -12.713378         -1.125112        -78.395714        -26.167646          5.994332         11.803858          0.059083         -0.069676        -22.541073        -12.665103   \n",
      "4              -9.929172        -21.326092          5.096616         34.600979         17.306837         32.940338         28.054308         13.004328         26.713232         15.217257         22.362494         -0.495710         -2.369125        -12.174193         20.268078   \n",
      "5              22.122725          8.197057         14.329684         -9.068298         -4.007388         22.945711          9.242973        -17.963694        -15.594984          3.877499        -22.675280         30.793562         -4.644149          0.978814        -32.862698   \n",
      "6               1.895731         -3.503023          4.633248          3.454958        -12.527353         12.516392          4.845756         -8.393820         -0.386358          4.530501          1.220961          5.314219         -3.616660          0.645246         10.453796   \n",
      "7             -27.835409         16.465067        -28.619335        -29.794931         39.842098         17.641155         37.525562        -27.923576        -84.548676         38.309402         -0.507248          6.608346        -29.138176         -9.039236          5.102618   \n",
      "8             -13.409509         16.950939        -35.555222         22.701273         -0.272171        -25.528433         30.619352         38.024635        -43.285225         20.831520          0.400742         12.053043        -60.718395         45.210812        -19.483078   \n",
      "9              10.066779         -2.816130          6.712364         11.226282          0.151560         -2.734974         -2.662063        -17.150286         -0.263672         17.376308         -0.902450         -2.937222         10.610524          2.442040          0.128769   \n",
      "...                  ...               ...               ...               ...               ...               ...               ...               ...               ...               ...               ...               ...               ...               ...               ...   \n",
      "899990        134.866608        126.167709        -98.292908        -34.904369          4.944379         65.661369        -86.592804       -304.960236        -26.196543        233.738419       -132.372604       -126.850060        117.188759       -136.488495       -191.295364   \n",
      "899991        -20.889471        -41.062477        -54.480049         14.439999        -22.275379         36.701698         37.358456         12.039186          2.025835          4.707228        -95.814034         17.517912        -61.618553        -18.816929         -7.456854   \n",
      "899992        -10.336445         18.907663        -41.024616        -41.738892         19.414419        -20.730068        -41.694950        -30.382761        -29.862207          8.361747         19.397570         80.370506        -43.067501          9.395530        -80.498848   \n",
      "899993          4.771066          5.180992         -7.965419        -13.728681          1.578449         -7.016149          3.323706        -22.987591        -29.754974         15.139371         -6.374556          2.245589         26.307667        -13.957544         -4.935371   \n",
      "899994         21.957514          2.322739         28.928541         -0.227955         -4.829550          3.410894         -6.905669        -70.872444        -27.883646         28.399279        -31.874939        -10.192326         21.646023        -35.399563        -16.820232   \n",
      "899995         18.303772         -6.650823         30.962355          2.354765        -14.645649         21.091599         13.409036         -1.352063          5.106390         -1.181238        -19.862165         39.029831         -9.467678        -31.128414        -21.542006   \n",
      "899996         -6.702850         11.768234         16.922012          5.370978        -27.157070         -5.277872         12.492964        -19.776091        -13.460461         -8.409258         15.655376          6.979224         26.083143         -7.004342          7.066779   \n",
      "899997         11.816083         -3.787890          7.283914         -7.542467          2.544457         -0.559207         -4.499887        -40.000866        -10.389032         20.365679        -26.393703         -6.714457          4.265721        -19.109478        -17.498325   \n",
      "899998         -0.216566         -1.142333         12.065594          7.161560         -9.781224         -1.724678          6.881351        -31.116959        -13.955484         -3.406502        -13.332582        -16.519260         17.077517        -27.730034          5.951789   \n",
      "899999          6.697263          1.683612         -9.184988        -13.046015          9.084881          6.776416         -1.032592        -14.600493         -9.366385         14.769855         -8.940232        -12.147880          5.300104         -4.450850          7.325218   \n",
      "\n",
      "        advertiser_id_61  advertiser_id_62  advertiser_id_63  \n",
      "0               7.532161          7.107622          1.284279  \n",
      "1              42.689655         31.789049         37.881310  \n",
      "2              -3.619370        -19.599323        -12.529618  \n",
      "3              21.770853         20.213200         10.026691  \n",
      "4              32.835140        -12.460931         27.394936  \n",
      "5              -3.974833          8.510688          1.567306  \n",
      "6              -5.385375          2.164699         -1.134294  \n",
      "7              28.504627          1.819767         40.314259  \n",
      "8             -25.140602         -1.389803         46.062859  \n",
      "9              -5.650247          5.505503          9.701681  \n",
      "...                  ...               ...               ...  \n",
      "899990        -43.286335        220.191544        -92.723640  \n",
      "899991         27.439184         13.583065         80.297676  \n",
      "899992        -38.166332        -47.953751          0.988093  \n",
      "899993          7.449057         -1.914723          0.554376  \n",
      "899994          1.852011         16.481792        -26.657505  \n",
      "899995        -34.711487        -16.292271          5.456914  \n",
      "899996         18.858204         11.441746        -17.007706  \n",
      "899997         14.887097         10.643560         -6.891002  \n",
      "899998          9.773966          7.907632        -18.708248  \n",
      "899999          5.439281         14.288554         -8.638039  \n",
      "\n",
      "[900000 rows x 85 columns]\n"
     ]
    }
   ],
   "source": [
    "train_df =pd.read_pickle('train3.pkl')\n",
    "train_df.replace(\"\\\\N\",-1,inplace=True)\n",
    "train_df=train_df.astype(float,inplace=True)\n",
    "train_df['age']  = train_df['age'] -1\n",
    "train_df['gender']  = train_df['gender'] -1\n",
    "\n",
    "print(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train_x_df = train_df.drop(['age','user_id','gender'], axis=1)\n",
    "#final_train_x_df = train_df.drop(['age','user_id','gender','active_days'], axis=1)\n",
    "final_train_y_df = train_df['gender']\n",
    "X_train, X_test, y_train, y_test = train_test_split(final_train_x_df, final_train_y_df, test_size=0.20, random_state=42)\n",
    "#train_data_show_df =train_df.drop(['active_days', 'click_times_total','max_clicked_industry_cnt','clicked_industry','clicked_advertiser','max_clicked_advertiser_cnt','max_clicked_industry_ratio','max_clicked_advertiser_ratio'], axis=1)\n",
    "#print(X_train)\n",
    "num_normal_features = ['_clicks_max_click_cnt','_max_clicked_ratio','_clicks_min_click_cnt','_min_clicked_ratio','_clicks_len','_clicks_mean','_clicks_median','_clicks_std']\n",
    "num_date_features  = [ '_clicks_max_click_cnt', '_clicks_min_click_cnt','_clicks_len','_clicks_mean','_clicks_median','_clicks_std']\n",
    "num_features = ['click_times_total'] +\\\n",
    "                [f'date{i}'  for i in num_date_features] + \\\n",
    "                [f'wday{i}'  for i in num_date_features] + \\\n",
    "                [f'month{i}'  for i in num_date_features] + \\\n",
    "                 [f'product_id{i}'  for i in num_normal_features] + \\\n",
    "                 [f'product_category{i}'  for i in num_normal_features] + \\\n",
    "                [f'industry{i}'  for i in num_normal_features] + \\\n",
    "                [f'advertiser_id{i}'  for i in num_normal_features]\n",
    "\n",
    "#print(num_features)\n",
    "\n",
    "c_features = ['industry_clicks_max_click','industry_clicks_min_click',\n",
    "              'advertiser_id_clicks_max_click','advertiser_id_clicks_min_click',\n",
    "              'product_id_clicks_max_click','product_id_clicks_min_click',\n",
    "              'product_category_clicks_max_click','product_category_clicks_min_click',\n",
    "             ]\n",
    "features= num_features + c_features\n",
    "#features= [f\"tfidf_{i}\" for i in range(317)] +['active_days','click_times_total']\n",
    "features= [f\"industry_{i}\" for i in range(16)] + [f\"advertiser_id_{i}\" for i in range(64)] +['active_days','click_times_total']\n",
    "#train_data = lgb.Dataset(final_train_x_df, label=final_train_y_df, feature_name=[   'max_clicked_industry', 'max_clicked_advertiser_id' ], categorical_feature=['max_clicked_industry','max_clicked_advertiser_id'])\n",
    "#train_data = lgb.Dataset(X_train, label=y_train, feature_name=features, categorical_feature=c_features,free_raw_data=False)\n",
    "train_data = lgb.Dataset(X_train, label=y_train, feature_name=features,free_raw_data=False)\n",
    "\n",
    "eval_data = lgb.Dataset(X_test, label=y_test, feature_name=features, categorical_feature=c_features,free_raw_data=False,reference=train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py:1205: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's multi_error: 0.330383\tvalid_1's multi_error: 0.330633\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[2]\ttraining's multi_error: 0.330383\tvalid_1's multi_error: 0.330633\n",
      "[3]\ttraining's multi_error: 0.327421\tvalid_1's multi_error: 0.327817\n",
      "[4]\ttraining's multi_error: 0.256446\tvalid_1's multi_error: 0.258794\n",
      "[5]\ttraining's multi_error: 0.219035\tvalid_1's multi_error: 0.221639\n",
      "[6]\ttraining's multi_error: 0.194422\tvalid_1's multi_error: 0.198078\n",
      "[7]\ttraining's multi_error: 0.180735\tvalid_1's multi_error: 0.184483\n",
      "[8]\ttraining's multi_error: 0.17096\tvalid_1's multi_error: 0.175483\n",
      "[9]\ttraining's multi_error: 0.163881\tvalid_1's multi_error: 0.168789\n",
      "[10]\ttraining's multi_error: 0.158443\tvalid_1's multi_error: 0.163533\n",
      "[11]\ttraining's multi_error: 0.154424\tvalid_1's multi_error: 0.159783\n",
      "[12]\ttraining's multi_error: 0.151129\tvalid_1's multi_error: 0.156683\n",
      "[13]\ttraining's multi_error: 0.14851\tvalid_1's multi_error: 0.154211\n",
      "[14]\ttraining's multi_error: 0.146322\tvalid_1's multi_error: 0.152333\n",
      "[15]\ttraining's multi_error: 0.144521\tvalid_1's multi_error: 0.150628\n",
      "[16]\ttraining's multi_error: 0.142736\tvalid_1's multi_error: 0.149044\n",
      "[17]\ttraining's multi_error: 0.141328\tvalid_1's multi_error: 0.147672\n",
      "[18]\ttraining's multi_error: 0.139972\tvalid_1's multi_error: 0.146689\n",
      "[19]\ttraining's multi_error: 0.138563\tvalid_1's multi_error: 0.145517\n",
      "[20]\ttraining's multi_error: 0.137371\tvalid_1's multi_error: 0.144606\n",
      "[21]\ttraining's multi_error: 0.136156\tvalid_1's multi_error: 0.143278\n",
      "[22]\ttraining's multi_error: 0.135092\tvalid_1's multi_error: 0.142739\n",
      "[23]\ttraining's multi_error: 0.134032\tvalid_1's multi_error: 0.141589\n",
      "[24]\ttraining's multi_error: 0.133025\tvalid_1's multi_error: 0.140883\n",
      "[25]\ttraining's multi_error: 0.13206\tvalid_1's multi_error: 0.140028\n",
      "[26]\ttraining's multi_error: 0.131093\tvalid_1's multi_error: 0.139094\n",
      "[27]\ttraining's multi_error: 0.130265\tvalid_1's multi_error: 0.13835\n",
      "[28]\ttraining's multi_error: 0.129408\tvalid_1's multi_error: 0.13755\n",
      "[29]\ttraining's multi_error: 0.128415\tvalid_1's multi_error: 0.137156\n",
      "[30]\ttraining's multi_error: 0.127747\tvalid_1's multi_error: 0.13635\n",
      "[31]\ttraining's multi_error: 0.127072\tvalid_1's multi_error: 0.135789\n",
      "[32]\ttraining's multi_error: 0.126265\tvalid_1's multi_error: 0.135306\n",
      "[33]\ttraining's multi_error: 0.125432\tvalid_1's multi_error: 0.13465\n",
      "[34]\ttraining's multi_error: 0.124735\tvalid_1's multi_error: 0.134106\n",
      "[35]\ttraining's multi_error: 0.124015\tvalid_1's multi_error: 0.133517\n",
      "[36]\ttraining's multi_error: 0.123232\tvalid_1's multi_error: 0.132972\n",
      "[37]\ttraining's multi_error: 0.122575\tvalid_1's multi_error: 0.132578\n",
      "[38]\ttraining's multi_error: 0.12204\tvalid_1's multi_error: 0.132128\n",
      "[39]\ttraining's multi_error: 0.121506\tvalid_1's multi_error: 0.131678\n",
      "[40]\ttraining's multi_error: 0.120954\tvalid_1's multi_error: 0.131322\n",
      "[41]\ttraining's multi_error: 0.12041\tvalid_1's multi_error: 0.131006\n",
      "[42]\ttraining's multi_error: 0.119792\tvalid_1's multi_error: 0.130706\n",
      "[43]\ttraining's multi_error: 0.119282\tvalid_1's multi_error: 0.130189\n",
      "[44]\ttraining's multi_error: 0.118756\tvalid_1's multi_error: 0.129767\n",
      "[45]\ttraining's multi_error: 0.118269\tvalid_1's multi_error: 0.129506\n",
      "[46]\ttraining's multi_error: 0.117782\tvalid_1's multi_error: 0.129256\n",
      "[47]\ttraining's multi_error: 0.117286\tvalid_1's multi_error: 0.129117\n",
      "[48]\ttraining's multi_error: 0.116836\tvalid_1's multi_error: 0.128661\n",
      "[49]\ttraining's multi_error: 0.116381\tvalid_1's multi_error: 0.128422\n",
      "[50]\ttraining's multi_error: 0.115853\tvalid_1's multi_error: 0.127967\n",
      "[51]\ttraining's multi_error: 0.115431\tvalid_1's multi_error: 0.127844\n",
      "[52]\ttraining's multi_error: 0.115024\tvalid_1's multi_error: 0.127606\n",
      "[53]\ttraining's multi_error: 0.114626\tvalid_1's multi_error: 0.127272\n",
      "[54]\ttraining's multi_error: 0.114226\tvalid_1's multi_error: 0.1271\n",
      "[55]\ttraining's multi_error: 0.113751\tvalid_1's multi_error: 0.126739\n",
      "[56]\ttraining's multi_error: 0.113381\tvalid_1's multi_error: 0.126344\n",
      "[57]\ttraining's multi_error: 0.112985\tvalid_1's multi_error: 0.12605\n",
      "[58]\ttraining's multi_error: 0.112618\tvalid_1's multi_error: 0.125772\n",
      "[59]\ttraining's multi_error: 0.112261\tvalid_1's multi_error: 0.125483\n",
      "[60]\ttraining's multi_error: 0.111888\tvalid_1's multi_error: 0.125261\n",
      "[61]\ttraining's multi_error: 0.111544\tvalid_1's multi_error: 0.125206\n",
      "[62]\ttraining's multi_error: 0.111125\tvalid_1's multi_error: 0.12485\n",
      "[63]\ttraining's multi_error: 0.110821\tvalid_1's multi_error: 0.124667\n",
      "[64]\ttraining's multi_error: 0.11054\tvalid_1's multi_error: 0.124389\n",
      "[65]\ttraining's multi_error: 0.110154\tvalid_1's multi_error: 0.124306\n",
      "[66]\ttraining's multi_error: 0.109735\tvalid_1's multi_error: 0.123983\n",
      "[67]\ttraining's multi_error: 0.109339\tvalid_1's multi_error: 0.123733\n",
      "[68]\ttraining's multi_error: 0.109024\tvalid_1's multi_error: 0.123583\n",
      "[69]\ttraining's multi_error: 0.108647\tvalid_1's multi_error: 0.123261\n",
      "[70]\ttraining's multi_error: 0.108304\tvalid_1's multi_error: 0.12305\n",
      "[71]\ttraining's multi_error: 0.107957\tvalid_1's multi_error: 0.122989\n",
      "[72]\ttraining's multi_error: 0.107674\tvalid_1's multi_error: 0.122817\n",
      "[73]\ttraining's multi_error: 0.107394\tvalid_1's multi_error: 0.122622\n",
      "[74]\ttraining's multi_error: 0.107033\tvalid_1's multi_error: 0.122494\n",
      "[75]\ttraining's multi_error: 0.106683\tvalid_1's multi_error: 0.122233\n",
      "[76]\ttraining's multi_error: 0.106407\tvalid_1's multi_error: 0.121944\n",
      "[77]\ttraining's multi_error: 0.106057\tvalid_1's multi_error: 0.121761\n",
      "[78]\ttraining's multi_error: 0.105857\tvalid_1's multi_error: 0.121683\n",
      "[79]\ttraining's multi_error: 0.105561\tvalid_1's multi_error: 0.121339\n",
      "[80]\ttraining's multi_error: 0.105207\tvalid_1's multi_error: 0.121278\n",
      "[81]\ttraining's multi_error: 0.104982\tvalid_1's multi_error: 0.120961\n",
      "[82]\ttraining's multi_error: 0.1047\tvalid_1's multi_error: 0.120956\n",
      "[83]\ttraining's multi_error: 0.104408\tvalid_1's multi_error: 0.120961\n",
      "[84]\ttraining's multi_error: 0.104143\tvalid_1's multi_error: 0.12085\n",
      "[85]\ttraining's multi_error: 0.103843\tvalid_1's multi_error: 0.120761\n",
      "[86]\ttraining's multi_error: 0.103533\tvalid_1's multi_error: 0.120467\n",
      "[87]\ttraining's multi_error: 0.103307\tvalid_1's multi_error: 0.120328\n",
      "[88]\ttraining's multi_error: 0.102961\tvalid_1's multi_error: 0.120144\n",
      "[89]\ttraining's multi_error: 0.102683\tvalid_1's multi_error: 0.120128\n",
      "[90]\ttraining's multi_error: 0.102536\tvalid_1's multi_error: 0.120039\n",
      "[91]\ttraining's multi_error: 0.102292\tvalid_1's multi_error: 0.119983\n",
      "[92]\ttraining's multi_error: 0.102043\tvalid_1's multi_error: 0.119894\n",
      "[93]\ttraining's multi_error: 0.101803\tvalid_1's multi_error: 0.119678\n",
      "[94]\ttraining's multi_error: 0.101522\tvalid_1's multi_error: 0.119594\n",
      "[95]\ttraining's multi_error: 0.101274\tvalid_1's multi_error: 0.119578\n",
      "[96]\ttraining's multi_error: 0.101053\tvalid_1's multi_error: 0.119472\n",
      "[97]\ttraining's multi_error: 0.100775\tvalid_1's multi_error: 0.119428\n",
      "[98]\ttraining's multi_error: 0.100487\tvalid_1's multi_error: 0.119406\n",
      "[99]\ttraining's multi_error: 0.100235\tvalid_1's multi_error: 0.119394\n",
      "[100]\ttraining's multi_error: 0.0999708\tvalid_1's multi_error: 0.119261\n",
      "[101]\ttraining's multi_error: 0.09975\tvalid_1's multi_error: 0.119056\n",
      "[102]\ttraining's multi_error: 0.0995181\tvalid_1's multi_error: 0.11905\n",
      "[103]\ttraining's multi_error: 0.0993264\tvalid_1's multi_error: 0.11885\n",
      "[104]\ttraining's multi_error: 0.0991278\tvalid_1's multi_error: 0.118833\n",
      "[105]\ttraining's multi_error: 0.0989181\tvalid_1's multi_error: 0.118672\n",
      "[106]\ttraining's multi_error: 0.0987389\tvalid_1's multi_error: 0.118522\n",
      "[107]\ttraining's multi_error: 0.0984667\tvalid_1's multi_error: 0.1184\n",
      "[108]\ttraining's multi_error: 0.0982722\tvalid_1's multi_error: 0.118417\n",
      "[109]\ttraining's multi_error: 0.0981042\tvalid_1's multi_error: 0.118372\n",
      "[110]\ttraining's multi_error: 0.0978458\tvalid_1's multi_error: 0.118139\n",
      "[111]\ttraining's multi_error: 0.0976569\tvalid_1's multi_error: 0.118083\n",
      "[112]\ttraining's multi_error: 0.0974278\tvalid_1's multi_error: 0.118022\n",
      "[113]\ttraining's multi_error: 0.0971917\tvalid_1's multi_error: 0.117894\n",
      "[114]\ttraining's multi_error: 0.0970028\tvalid_1's multi_error: 0.117744\n",
      "[115]\ttraining's multi_error: 0.0968222\tvalid_1's multi_error: 0.117522\n",
      "[116]\ttraining's multi_error: 0.0966125\tvalid_1's multi_error: 0.117506\n",
      "[117]\ttraining's multi_error: 0.0963153\tvalid_1's multi_error: 0.117689\n",
      "[118]\ttraining's multi_error: 0.0961306\tvalid_1's multi_error: 0.117572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[119]\ttraining's multi_error: 0.0959833\tvalid_1's multi_error: 0.117539\n",
      "[120]\ttraining's multi_error: 0.0958139\tvalid_1's multi_error: 0.1176\n",
      "[121]\ttraining's multi_error: 0.0955819\tvalid_1's multi_error: 0.117478\n",
      "[122]\ttraining's multi_error: 0.0953403\tvalid_1's multi_error: 0.117394\n",
      "[123]\ttraining's multi_error: 0.0950944\tvalid_1's multi_error: 0.117372\n",
      "[124]\ttraining's multi_error: 0.0949069\tvalid_1's multi_error: 0.117294\n",
      "[125]\ttraining's multi_error: 0.0947125\tvalid_1's multi_error: 0.117128\n",
      "[126]\ttraining's multi_error: 0.0945639\tvalid_1's multi_error: 0.117156\n",
      "[127]\ttraining's multi_error: 0.0943861\tvalid_1's multi_error: 0.117056\n",
      "[128]\ttraining's multi_error: 0.0941736\tvalid_1's multi_error: 0.116972\n",
      "[129]\ttraining's multi_error: 0.0939569\tvalid_1's multi_error: 0.116761\n",
      "[130]\ttraining's multi_error: 0.0938194\tvalid_1's multi_error: 0.116756\n",
      "[131]\ttraining's multi_error: 0.0936264\tvalid_1's multi_error: 0.116689\n",
      "[132]\ttraining's multi_error: 0.0934611\tvalid_1's multi_error: 0.116694\n",
      "[133]\ttraining's multi_error: 0.0932028\tvalid_1's multi_error: 0.116844\n",
      "[134]\ttraining's multi_error: 0.0929222\tvalid_1's multi_error: 0.116883\n",
      "[135]\ttraining's multi_error: 0.0927194\tvalid_1's multi_error: 0.1167\n",
      "[136]\ttraining's multi_error: 0.092475\tvalid_1's multi_error: 0.116483\n",
      "[137]\ttraining's multi_error: 0.0923278\tvalid_1's multi_error: 0.11625\n",
      "[138]\ttraining's multi_error: 0.0921181\tvalid_1's multi_error: 0.116178\n",
      "[139]\ttraining's multi_error: 0.0918806\tvalid_1's multi_error: 0.1163\n",
      "[140]\ttraining's multi_error: 0.0917819\tvalid_1's multi_error: 0.116133\n",
      "[141]\ttraining's multi_error: 0.0915611\tvalid_1's multi_error: 0.116061\n",
      "[142]\ttraining's multi_error: 0.0913778\tvalid_1's multi_error: 0.116039\n",
      "[143]\ttraining's multi_error: 0.0911847\tvalid_1's multi_error: 0.116011\n",
      "[144]\ttraining's multi_error: 0.0910139\tvalid_1's multi_error: 0.115967\n",
      "[145]\ttraining's multi_error: 0.0908486\tvalid_1's multi_error: 0.115844\n",
      "[146]\ttraining's multi_error: 0.0906583\tvalid_1's multi_error: 0.115761\n",
      "[147]\ttraining's multi_error: 0.0904431\tvalid_1's multi_error: 0.115622\n",
      "[148]\ttraining's multi_error: 0.0902486\tvalid_1's multi_error: 0.115583\n",
      "[149]\ttraining's multi_error: 0.0900903\tvalid_1's multi_error: 0.115661\n",
      "[150]\ttraining's multi_error: 0.08995\tvalid_1's multi_error: 0.115639\n",
      "[151]\ttraining's multi_error: 0.0897514\tvalid_1's multi_error: 0.115556\n",
      "[152]\ttraining's multi_error: 0.0895792\tvalid_1's multi_error: 0.115439\n",
      "[153]\ttraining's multi_error: 0.0893667\tvalid_1's multi_error: 0.1154\n",
      "[154]\ttraining's multi_error: 0.0891931\tvalid_1's multi_error: 0.115278\n",
      "[155]\ttraining's multi_error: 0.0889889\tvalid_1's multi_error: 0.115339\n",
      "[156]\ttraining's multi_error: 0.0888625\tvalid_1's multi_error: 0.115244\n",
      "[157]\ttraining's multi_error: 0.0886764\tvalid_1's multi_error: 0.115189\n",
      "[158]\ttraining's multi_error: 0.0885042\tvalid_1's multi_error: 0.115189\n",
      "[159]\ttraining's multi_error: 0.0882847\tvalid_1's multi_error: 0.115239\n",
      "[160]\ttraining's multi_error: 0.0881056\tvalid_1's multi_error: 0.1152\n",
      "[161]\ttraining's multi_error: 0.0879347\tvalid_1's multi_error: 0.115144\n",
      "[162]\ttraining's multi_error: 0.0877361\tvalid_1's multi_error: 0.115067\n",
      "[163]\ttraining's multi_error: 0.0875139\tvalid_1's multi_error: 0.115061\n",
      "[164]\ttraining's multi_error: 0.0873542\tvalid_1's multi_error: 0.115083\n",
      "[165]\ttraining's multi_error: 0.08715\tvalid_1's multi_error: 0.115022\n",
      "[166]\ttraining's multi_error: 0.0870014\tvalid_1's multi_error: 0.114828\n",
      "[167]\ttraining's multi_error: 0.0867806\tvalid_1's multi_error: 0.114778\n",
      "[168]\ttraining's multi_error: 0.0866264\tvalid_1's multi_error: 0.114744\n",
      "[169]\ttraining's multi_error: 0.0864611\tvalid_1's multi_error: 0.114744\n",
      "[170]\ttraining's multi_error: 0.0863083\tvalid_1's multi_error: 0.11465\n",
      "[171]\ttraining's multi_error: 0.0861361\tvalid_1's multi_error: 0.114722\n",
      "[172]\ttraining's multi_error: 0.0860181\tvalid_1's multi_error: 0.114772\n",
      "[173]\ttraining's multi_error: 0.0857833\tvalid_1's multi_error: 0.114772\n",
      "[174]\ttraining's multi_error: 0.0855931\tvalid_1's multi_error: 0.1148\n",
      "[175]\ttraining's multi_error: 0.085475\tvalid_1's multi_error: 0.11465\n",
      "[176]\ttraining's multi_error: 0.0853056\tvalid_1's multi_error: 0.114589\n",
      "[177]\ttraining's multi_error: 0.0851069\tvalid_1's multi_error: 0.114522\n",
      "[178]\ttraining's multi_error: 0.0849194\tvalid_1's multi_error: 0.114472\n",
      "[179]\ttraining's multi_error: 0.0847875\tvalid_1's multi_error: 0.114406\n",
      "[180]\ttraining's multi_error: 0.0845625\tvalid_1's multi_error: 0.114383\n",
      "[181]\ttraining's multi_error: 0.0843917\tvalid_1's multi_error: 0.114289\n",
      "[182]\ttraining's multi_error: 0.0842222\tvalid_1's multi_error: 0.114244\n",
      "[183]\ttraining's multi_error: 0.0840208\tvalid_1's multi_error: 0.114211\n",
      "[184]\ttraining's multi_error: 0.083875\tvalid_1's multi_error: 0.114194\n",
      "[185]\ttraining's multi_error: 0.0837514\tvalid_1's multi_error: 0.114222\n",
      "[186]\ttraining's multi_error: 0.0835972\tvalid_1's multi_error: 0.114272\n",
      "[187]\ttraining's multi_error: 0.0834639\tvalid_1's multi_error: 0.1142\n",
      "[188]\ttraining's multi_error: 0.0832931\tvalid_1's multi_error: 0.114167\n",
      "[189]\ttraining's multi_error: 0.0830847\tvalid_1's multi_error: 0.114122\n",
      "[190]\ttraining's multi_error: 0.0829708\tvalid_1's multi_error: 0.114222\n",
      "[191]\ttraining's multi_error: 0.0827444\tvalid_1's multi_error: 0.114094\n",
      "[192]\ttraining's multi_error: 0.0826125\tvalid_1's multi_error: 0.114128\n",
      "[193]\ttraining's multi_error: 0.0824458\tvalid_1's multi_error: 0.114139\n",
      "[194]\ttraining's multi_error: 0.0823125\tvalid_1's multi_error: 0.114294\n",
      "[195]\ttraining's multi_error: 0.0821236\tvalid_1's multi_error: 0.114178\n",
      "[196]\ttraining's multi_error: 0.0820097\tvalid_1's multi_error: 0.11405\n",
      "[197]\ttraining's multi_error: 0.0818306\tvalid_1's multi_error: 0.114044\n",
      "[198]\ttraining's multi_error: 0.0816431\tvalid_1's multi_error: 0.11395\n",
      "[199]\ttraining's multi_error: 0.0814611\tvalid_1's multi_error: 0.113894\n",
      "[200]\ttraining's multi_error: 0.0813306\tvalid_1's multi_error: 0.113944\n",
      "[201]\ttraining's multi_error: 0.0811917\tvalid_1's multi_error: 0.113911\n",
      "[202]\ttraining's multi_error: 0.0810125\tvalid_1's multi_error: 0.11385\n",
      "[203]\ttraining's multi_error: 0.0808333\tvalid_1's multi_error: 0.11395\n",
      "[204]\ttraining's multi_error: 0.0807069\tvalid_1's multi_error: 0.113856\n",
      "[205]\ttraining's multi_error: 0.0805597\tvalid_1's multi_error: 0.113794\n",
      "[206]\ttraining's multi_error: 0.0803792\tvalid_1's multi_error: 0.113678\n",
      "[207]\ttraining's multi_error: 0.0801875\tvalid_1's multi_error: 0.113678\n",
      "[208]\ttraining's multi_error: 0.0800278\tvalid_1's multi_error: 0.113606\n",
      "[209]\ttraining's multi_error: 0.0798181\tvalid_1's multi_error: 0.113567\n",
      "[210]\ttraining's multi_error: 0.0796583\tvalid_1's multi_error: 0.113544\n",
      "[211]\ttraining's multi_error: 0.0795264\tvalid_1's multi_error: 0.113611\n",
      "[212]\ttraining's multi_error: 0.0793694\tvalid_1's multi_error: 0.113511\n",
      "[213]\ttraining's multi_error: 0.0792347\tvalid_1's multi_error: 0.113533\n",
      "[214]\ttraining's multi_error: 0.0791333\tvalid_1's multi_error: 0.113611\n",
      "[215]\ttraining's multi_error: 0.0789333\tvalid_1's multi_error: 0.1136\n",
      "[216]\ttraining's multi_error: 0.0788236\tvalid_1's multi_error: 0.113633\n",
      "[217]\ttraining's multi_error: 0.0787056\tvalid_1's multi_error: 0.113561\n",
      "[218]\ttraining's multi_error: 0.0785472\tvalid_1's multi_error: 0.113583\n",
      "[219]\ttraining's multi_error: 0.0783944\tvalid_1's multi_error: 0.113489\n",
      "[220]\ttraining's multi_error: 0.0782444\tvalid_1's multi_error: 0.113489\n",
      "[221]\ttraining's multi_error: 0.0781583\tvalid_1's multi_error: 0.113428\n",
      "[222]\ttraining's multi_error: 0.0779597\tvalid_1's multi_error: 0.113422\n",
      "[223]\ttraining's multi_error: 0.0778014\tvalid_1's multi_error: 0.113344\n",
      "[224]\ttraining's multi_error: 0.0776139\tvalid_1's multi_error: 0.113311\n",
      "[225]\ttraining's multi_error: 0.0774681\tvalid_1's multi_error: 0.113339\n",
      "[226]\ttraining's multi_error: 0.0772833\tvalid_1's multi_error: 0.1134\n",
      "[227]\ttraining's multi_error: 0.0771819\tvalid_1's multi_error: 0.113328\n",
      "[228]\ttraining's multi_error: 0.0770403\tvalid_1's multi_error: 0.113339\n",
      "[229]\ttraining's multi_error: 0.0768972\tvalid_1's multi_error: 0.113383\n",
      "[230]\ttraining's multi_error: 0.0766417\tvalid_1's multi_error: 0.113344\n",
      "[231]\ttraining's multi_error: 0.0764806\tvalid_1's multi_error: 0.113378\n",
      "[232]\ttraining's multi_error: 0.0763417\tvalid_1's multi_error: 0.113367\n",
      "[233]\ttraining's multi_error: 0.0761861\tvalid_1's multi_error: 0.11345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[234]\ttraining's multi_error: 0.0760444\tvalid_1's multi_error: 0.113367\n",
      "[235]\ttraining's multi_error: 0.0759278\tvalid_1's multi_error: 0.113394\n",
      "[236]\ttraining's multi_error: 0.0757792\tvalid_1's multi_error: 0.113478\n",
      "[237]\ttraining's multi_error: 0.0755569\tvalid_1's multi_error: 0.113378\n",
      "[238]\ttraining's multi_error: 0.0753875\tvalid_1's multi_error: 0.113367\n",
      "[239]\ttraining's multi_error: 0.0751931\tvalid_1's multi_error: 0.113361\n",
      "[240]\ttraining's multi_error: 0.0750639\tvalid_1's multi_error: 0.1133\n",
      "[241]\ttraining's multi_error: 0.0749111\tvalid_1's multi_error: 0.113183\n",
      "[242]\ttraining's multi_error: 0.0747528\tvalid_1's multi_error: 0.113222\n",
      "[243]\ttraining's multi_error: 0.0746236\tvalid_1's multi_error: 0.1132\n",
      "[244]\ttraining's multi_error: 0.074475\tvalid_1's multi_error: 0.113111\n",
      "[245]\ttraining's multi_error: 0.0743181\tvalid_1's multi_error: 0.113189\n",
      "[246]\ttraining's multi_error: 0.0741486\tvalid_1's multi_error: 0.1132\n",
      "[247]\ttraining's multi_error: 0.0739819\tvalid_1's multi_error: 0.113178\n",
      "[248]\ttraining's multi_error: 0.0738875\tvalid_1's multi_error: 0.113128\n",
      "[249]\ttraining's multi_error: 0.0737569\tvalid_1's multi_error: 0.113144\n",
      "[250]\ttraining's multi_error: 0.0735764\tvalid_1's multi_error: 0.113056\n",
      "[251]\ttraining's multi_error: 0.0734\tvalid_1's multi_error: 0.113122\n",
      "[252]\ttraining's multi_error: 0.0733083\tvalid_1's multi_error: 0.113067\n",
      "[253]\ttraining's multi_error: 0.0731528\tvalid_1's multi_error: 0.113056\n",
      "[254]\ttraining's multi_error: 0.0729722\tvalid_1's multi_error: 0.112844\n",
      "[255]\ttraining's multi_error: 0.0728778\tvalid_1's multi_error: 0.112917\n",
      "[256]\ttraining's multi_error: 0.0727292\tvalid_1's multi_error: 0.113011\n",
      "[257]\ttraining's multi_error: 0.0725931\tvalid_1's multi_error: 0.112933\n",
      "[258]\ttraining's multi_error: 0.0724319\tvalid_1's multi_error: 0.112894\n",
      "[259]\ttraining's multi_error: 0.0722861\tvalid_1's multi_error: 0.112883\n",
      "[260]\ttraining's multi_error: 0.0721292\tvalid_1's multi_error: 0.112844\n",
      "[261]\ttraining's multi_error: 0.0719403\tvalid_1's multi_error: 0.112922\n",
      "[262]\ttraining's multi_error: 0.0718167\tvalid_1's multi_error: 0.112933\n",
      "[263]\ttraining's multi_error: 0.0716625\tvalid_1's multi_error: 0.112906\n",
      "[264]\ttraining's multi_error: 0.0715347\tvalid_1's multi_error: 0.112894\n",
      "[265]\ttraining's multi_error: 0.0714375\tvalid_1's multi_error: 0.112978\n",
      "[266]\ttraining's multi_error: 0.0712639\tvalid_1's multi_error: 0.1129\n",
      "[267]\ttraining's multi_error: 0.0710819\tvalid_1's multi_error: 0.112922\n",
      "[268]\ttraining's multi_error: 0.0709403\tvalid_1's multi_error: 0.112967\n",
      "[269]\ttraining's multi_error: 0.0707778\tvalid_1's multi_error: 0.112906\n",
      "[270]\ttraining's multi_error: 0.0706458\tvalid_1's multi_error: 0.112806\n",
      "[271]\ttraining's multi_error: 0.0704972\tvalid_1's multi_error: 0.112783\n",
      "[272]\ttraining's multi_error: 0.0702444\tvalid_1's multi_error: 0.112767\n",
      "[273]\ttraining's multi_error: 0.0700542\tvalid_1's multi_error: 0.112694\n",
      "[274]\ttraining's multi_error: 0.0698847\tvalid_1's multi_error: 0.112633\n",
      "[275]\ttraining's multi_error: 0.0697292\tvalid_1's multi_error: 0.112678\n",
      "[276]\ttraining's multi_error: 0.0695792\tvalid_1's multi_error: 0.112622\n",
      "[277]\ttraining's multi_error: 0.0694403\tvalid_1's multi_error: 0.112639\n",
      "[278]\ttraining's multi_error: 0.0693083\tvalid_1's multi_error: 0.112522\n",
      "[279]\ttraining's multi_error: 0.0691917\tvalid_1's multi_error: 0.112494\n",
      "[280]\ttraining's multi_error: 0.0690306\tvalid_1's multi_error: 0.112628\n",
      "[281]\ttraining's multi_error: 0.0688861\tvalid_1's multi_error: 0.112628\n",
      "[282]\ttraining's multi_error: 0.0687056\tvalid_1's multi_error: 0.112578\n",
      "[283]\ttraining's multi_error: 0.0685806\tvalid_1's multi_error: 0.112528\n",
      "[284]\ttraining's multi_error: 0.0684306\tvalid_1's multi_error: 0.112539\n",
      "[285]\ttraining's multi_error: 0.0682667\tvalid_1's multi_error: 0.112517\n",
      "[286]\ttraining's multi_error: 0.0680903\tvalid_1's multi_error: 0.112467\n",
      "[287]\ttraining's multi_error: 0.0679167\tvalid_1's multi_error: 0.112456\n",
      "[288]\ttraining's multi_error: 0.0677361\tvalid_1's multi_error: 0.112467\n",
      "[289]\ttraining's multi_error: 0.0675736\tvalid_1's multi_error: 0.112494\n",
      "[290]\ttraining's multi_error: 0.0674125\tvalid_1's multi_error: 0.112433\n",
      "[291]\ttraining's multi_error: 0.0672833\tvalid_1's multi_error: 0.1124\n",
      "[292]\ttraining's multi_error: 0.0671778\tvalid_1's multi_error: 0.112306\n",
      "[293]\ttraining's multi_error: 0.0670583\tvalid_1's multi_error: 0.112294\n",
      "[294]\ttraining's multi_error: 0.0669083\tvalid_1's multi_error: 0.112317\n",
      "[295]\ttraining's multi_error: 0.0667583\tvalid_1's multi_error: 0.112417\n",
      "[296]\ttraining's multi_error: 0.0666139\tvalid_1's multi_error: 0.112439\n",
      "[297]\ttraining's multi_error: 0.0665375\tvalid_1's multi_error: 0.112467\n",
      "[298]\ttraining's multi_error: 0.0663778\tvalid_1's multi_error: 0.112461\n",
      "[299]\ttraining's multi_error: 0.0662806\tvalid_1's multi_error: 0.112289\n",
      "[300]\ttraining's multi_error: 0.0660958\tvalid_1's multi_error: 0.112289\n",
      "[301]\ttraining's multi_error: 0.0659792\tvalid_1's multi_error: 0.112178\n",
      "[302]\ttraining's multi_error: 0.0658361\tvalid_1's multi_error: 0.1122\n",
      "[303]\ttraining's multi_error: 0.0656667\tvalid_1's multi_error: 0.112228\n",
      "[304]\ttraining's multi_error: 0.065575\tvalid_1's multi_error: 0.1122\n",
      "[305]\ttraining's multi_error: 0.0654083\tvalid_1's multi_error: 0.112217\n",
      "[306]\ttraining's multi_error: 0.0652069\tvalid_1's multi_error: 0.112272\n",
      "[307]\ttraining's multi_error: 0.0650861\tvalid_1's multi_error: 0.112189\n",
      "[308]\ttraining's multi_error: 0.0649083\tvalid_1's multi_error: 0.112139\n",
      "[309]\ttraining's multi_error: 0.0647472\tvalid_1's multi_error: 0.112089\n",
      "[310]\ttraining's multi_error: 0.0646764\tvalid_1's multi_error: 0.112172\n",
      "[311]\ttraining's multi_error: 0.0645014\tvalid_1's multi_error: 0.112172\n",
      "[312]\ttraining's multi_error: 0.0643667\tvalid_1's multi_error: 0.112183\n",
      "[313]\ttraining's multi_error: 0.0642319\tvalid_1's multi_error: 0.112139\n",
      "[314]\ttraining's multi_error: 0.0641222\tvalid_1's multi_error: 0.112094\n",
      "[315]\ttraining's multi_error: 0.0639792\tvalid_1's multi_error: 0.112067\n",
      "[316]\ttraining's multi_error: 0.0638222\tvalid_1's multi_error: 0.11215\n",
      "[317]\ttraining's multi_error: 0.0636944\tvalid_1's multi_error: 0.112106\n",
      "[318]\ttraining's multi_error: 0.0635764\tvalid_1's multi_error: 0.112189\n",
      "[319]\ttraining's multi_error: 0.0634667\tvalid_1's multi_error: 0.11215\n",
      "[320]\ttraining's multi_error: 0.0633722\tvalid_1's multi_error: 0.112172\n",
      "[321]\ttraining's multi_error: 0.0632153\tvalid_1's multi_error: 0.112139\n",
      "[322]\ttraining's multi_error: 0.0630778\tvalid_1's multi_error: 0.112183\n",
      "[323]\ttraining's multi_error: 0.0629792\tvalid_1's multi_error: 0.112139\n",
      "[324]\ttraining's multi_error: 0.0628306\tvalid_1's multi_error: 0.1121\n",
      "[325]\ttraining's multi_error: 0.0627167\tvalid_1's multi_error: 0.112\n",
      "[326]\ttraining's multi_error: 0.0625569\tvalid_1's multi_error: 0.111956\n",
      "[327]\ttraining's multi_error: 0.0624\tvalid_1's multi_error: 0.111844\n",
      "[328]\ttraining's multi_error: 0.0622236\tvalid_1's multi_error: 0.111883\n",
      "[329]\ttraining's multi_error: 0.0621194\tvalid_1's multi_error: 0.1119\n",
      "[330]\ttraining's multi_error: 0.0619986\tvalid_1's multi_error: 0.112028\n",
      "[331]\ttraining's multi_error: 0.0618347\tvalid_1's multi_error: 0.111983\n",
      "[332]\ttraining's multi_error: 0.0616583\tvalid_1's multi_error: 0.111922\n",
      "[333]\ttraining's multi_error: 0.0615097\tvalid_1's multi_error: 0.112039\n",
      "[334]\ttraining's multi_error: 0.0613222\tvalid_1's multi_error: 0.112178\n",
      "[335]\ttraining's multi_error: 0.0612056\tvalid_1's multi_error: 0.112172\n",
      "[336]\ttraining's multi_error: 0.0610514\tvalid_1's multi_error: 0.112144\n",
      "[337]\ttraining's multi_error: 0.0609319\tvalid_1's multi_error: 0.112094\n",
      "[338]\ttraining's multi_error: 0.0607958\tvalid_1's multi_error: 0.112006\n",
      "[339]\ttraining's multi_error: 0.0605958\tvalid_1's multi_error: 0.112056\n",
      "[340]\ttraining's multi_error: 0.0604556\tvalid_1's multi_error: 0.111989\n",
      "[341]\ttraining's multi_error: 0.0603306\tvalid_1's multi_error: 0.112067\n",
      "[342]\ttraining's multi_error: 0.0602319\tvalid_1's multi_error: 0.111917\n",
      "[343]\ttraining's multi_error: 0.0601583\tvalid_1's multi_error: 0.111872\n",
      "[344]\ttraining's multi_error: 0.0600042\tvalid_1's multi_error: 0.111883\n",
      "[345]\ttraining's multi_error: 0.0598347\tvalid_1's multi_error: 0.11195\n",
      "[346]\ttraining's multi_error: 0.0596514\tvalid_1's multi_error: 0.111944\n",
      "[347]\ttraining's multi_error: 0.0595639\tvalid_1's multi_error: 0.111911\n",
      "[348]\ttraining's multi_error: 0.0594319\tvalid_1's multi_error: 0.111967\n",
      "[349]\ttraining's multi_error: 0.0592889\tvalid_1's multi_error: 0.111956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[350]\ttraining's multi_error: 0.0591236\tvalid_1's multi_error: 0.111956\n",
      "[351]\ttraining's multi_error: 0.0589931\tvalid_1's multi_error: 0.111844\n",
      "[352]\ttraining's multi_error: 0.05885\tvalid_1's multi_error: 0.11175\n",
      "[353]\ttraining's multi_error: 0.0587389\tvalid_1's multi_error: 0.111844\n",
      "[354]\ttraining's multi_error: 0.0585583\tvalid_1's multi_error: 0.111794\n",
      "[355]\ttraining's multi_error: 0.0584014\tvalid_1's multi_error: 0.1118\n",
      "[356]\ttraining's multi_error: 0.0582875\tvalid_1's multi_error: 0.111861\n",
      "[357]\ttraining's multi_error: 0.0581903\tvalid_1's multi_error: 0.111867\n",
      "[358]\ttraining's multi_error: 0.0580889\tvalid_1's multi_error: 0.111867\n",
      "[359]\ttraining's multi_error: 0.0579625\tvalid_1's multi_error: 0.111822\n",
      "[360]\ttraining's multi_error: 0.0578111\tvalid_1's multi_error: 0.111817\n",
      "[361]\ttraining's multi_error: 0.0577319\tvalid_1's multi_error: 0.111911\n",
      "[362]\ttraining's multi_error: 0.0576208\tvalid_1's multi_error: 0.111917\n",
      "[363]\ttraining's multi_error: 0.0574444\tvalid_1's multi_error: 0.111822\n",
      "[364]\ttraining's multi_error: 0.0573208\tvalid_1's multi_error: 0.111872\n",
      "[365]\ttraining's multi_error: 0.0571986\tvalid_1's multi_error: 0.111878\n",
      "[366]\ttraining's multi_error: 0.0570694\tvalid_1's multi_error: 0.111789\n",
      "[367]\ttraining's multi_error: 0.05695\tvalid_1's multi_error: 0.11175\n",
      "[368]\ttraining's multi_error: 0.0568292\tvalid_1's multi_error: 0.111783\n",
      "[369]\ttraining's multi_error: 0.0567375\tvalid_1's multi_error: 0.111772\n",
      "[370]\ttraining's multi_error: 0.0565847\tvalid_1's multi_error: 0.11185\n",
      "[371]\ttraining's multi_error: 0.0564167\tvalid_1's multi_error: 0.111844\n",
      "[372]\ttraining's multi_error: 0.0562667\tvalid_1's multi_error: 0.111806\n",
      "[373]\ttraining's multi_error: 0.0561167\tvalid_1's multi_error: 0.111761\n",
      "[374]\ttraining's multi_error: 0.0559931\tvalid_1's multi_error: 0.1117\n",
      "[375]\ttraining's multi_error: 0.0559014\tvalid_1's multi_error: 0.111706\n",
      "[376]\ttraining's multi_error: 0.0557639\tvalid_1's multi_error: 0.111661\n",
      "[377]\ttraining's multi_error: 0.0556181\tvalid_1's multi_error: 0.111722\n",
      "[378]\ttraining's multi_error: 0.0555056\tvalid_1's multi_error: 0.111672\n",
      "[379]\ttraining's multi_error: 0.0553833\tvalid_1's multi_error: 0.111756\n",
      "[380]\ttraining's multi_error: 0.0552681\tvalid_1's multi_error: 0.111783\n",
      "[381]\ttraining's multi_error: 0.0551097\tvalid_1's multi_error: 0.111761\n",
      "[382]\ttraining's multi_error: 0.054975\tvalid_1's multi_error: 0.111811\n",
      "[383]\ttraining's multi_error: 0.05485\tvalid_1's multi_error: 0.111822\n",
      "[384]\ttraining's multi_error: 0.0546806\tvalid_1's multi_error: 0.111789\n",
      "[385]\ttraining's multi_error: 0.0545417\tvalid_1's multi_error: 0.111756\n",
      "[386]\ttraining's multi_error: 0.0544028\tvalid_1's multi_error: 0.111717\n",
      "[387]\ttraining's multi_error: 0.054275\tvalid_1's multi_error: 0.111683\n",
      "[388]\ttraining's multi_error: 0.0541583\tvalid_1's multi_error: 0.111717\n",
      "[389]\ttraining's multi_error: 0.0540236\tvalid_1's multi_error: 0.111678\n",
      "[390]\ttraining's multi_error: 0.0539222\tvalid_1's multi_error: 0.111617\n",
      "[391]\ttraining's multi_error: 0.0538292\tvalid_1's multi_error: 0.111728\n",
      "[392]\ttraining's multi_error: 0.0536792\tvalid_1's multi_error: 0.111744\n",
      "[393]\ttraining's multi_error: 0.0536028\tvalid_1's multi_error: 0.111761\n",
      "[394]\ttraining's multi_error: 0.0534528\tvalid_1's multi_error: 0.111806\n",
      "[395]\ttraining's multi_error: 0.0533514\tvalid_1's multi_error: 0.111744\n",
      "[396]\ttraining's multi_error: 0.0532486\tvalid_1's multi_error: 0.111706\n",
      "[397]\ttraining's multi_error: 0.0531125\tvalid_1's multi_error: 0.111772\n",
      "[398]\ttraining's multi_error: 0.0529847\tvalid_1's multi_error: 0.111772\n",
      "[399]\ttraining's multi_error: 0.052875\tvalid_1's multi_error: 0.111733\n",
      "[400]\ttraining's multi_error: 0.0527292\tvalid_1's multi_error: 0.111722\n",
      "[401]\ttraining's multi_error: 0.0525444\tvalid_1's multi_error: 0.111722\n",
      "[402]\ttraining's multi_error: 0.0524167\tvalid_1's multi_error: 0.111678\n",
      "[403]\ttraining's multi_error: 0.0522903\tvalid_1's multi_error: 0.111678\n",
      "[404]\ttraining's multi_error: 0.0521542\tvalid_1's multi_error: 0.111694\n",
      "[405]\ttraining's multi_error: 0.0520236\tvalid_1's multi_error: 0.111667\n",
      "[406]\ttraining's multi_error: 0.0518597\tvalid_1's multi_error: 0.111733\n",
      "[407]\ttraining's multi_error: 0.0517194\tvalid_1's multi_error: 0.111628\n",
      "[408]\ttraining's multi_error: 0.0516042\tvalid_1's multi_error: 0.11175\n",
      "[409]\ttraining's multi_error: 0.0514722\tvalid_1's multi_error: 0.111728\n",
      "[410]\ttraining's multi_error: 0.0513569\tvalid_1's multi_error: 0.111728\n",
      "[411]\ttraining's multi_error: 0.0512278\tvalid_1's multi_error: 0.111678\n",
      "[412]\ttraining's multi_error: 0.0511264\tvalid_1's multi_error: 0.111661\n",
      "[413]\ttraining's multi_error: 0.0510306\tvalid_1's multi_error: 0.111661\n",
      "[414]\ttraining's multi_error: 0.0509056\tvalid_1's multi_error: 0.1117\n",
      "[415]\ttraining's multi_error: 0.0507444\tvalid_1's multi_error: 0.111689\n",
      "[416]\ttraining's multi_error: 0.0505583\tvalid_1's multi_error: 0.111739\n",
      "[417]\ttraining's multi_error: 0.0504417\tvalid_1's multi_error: 0.111706\n",
      "[418]\ttraining's multi_error: 0.0503153\tvalid_1's multi_error: 0.111722\n",
      "[419]\ttraining's multi_error: 0.0502014\tvalid_1's multi_error: 0.111772\n",
      "[420]\ttraining's multi_error: 0.0501333\tvalid_1's multi_error: 0.111644\n",
      "[421]\ttraining's multi_error: 0.0499583\tvalid_1's multi_error: 0.111633\n",
      "[422]\ttraining's multi_error: 0.0498125\tvalid_1's multi_error: 0.111639\n",
      "[423]\ttraining's multi_error: 0.0496764\tvalid_1's multi_error: 0.1116\n",
      "[424]\ttraining's multi_error: 0.0495625\tvalid_1's multi_error: 0.111594\n",
      "[425]\ttraining's multi_error: 0.0494444\tvalid_1's multi_error: 0.111644\n",
      "[426]\ttraining's multi_error: 0.0492819\tvalid_1's multi_error: 0.111661\n",
      "[427]\ttraining's multi_error: 0.0491444\tvalid_1's multi_error: 0.111744\n",
      "[428]\ttraining's multi_error: 0.0490472\tvalid_1's multi_error: 0.111711\n",
      "[429]\ttraining's multi_error: 0.0489375\tvalid_1's multi_error: 0.111644\n",
      "[430]\ttraining's multi_error: 0.0488153\tvalid_1's multi_error: 0.111633\n",
      "[431]\ttraining's multi_error: 0.0487417\tvalid_1's multi_error: 0.111678\n",
      "[432]\ttraining's multi_error: 0.0486403\tvalid_1's multi_error: 0.11165\n",
      "[433]\ttraining's multi_error: 0.0485042\tvalid_1's multi_error: 0.111583\n",
      "[434]\ttraining's multi_error: 0.0483639\tvalid_1's multi_error: 0.111567\n",
      "[435]\ttraining's multi_error: 0.0482694\tvalid_1's multi_error: 0.11155\n",
      "[436]\ttraining's multi_error: 0.0481111\tvalid_1's multi_error: 0.111572\n",
      "[437]\ttraining's multi_error: 0.0479986\tvalid_1's multi_error: 0.111517\n",
      "[438]\ttraining's multi_error: 0.0478667\tvalid_1's multi_error: 0.111517\n",
      "[439]\ttraining's multi_error: 0.0477639\tvalid_1's multi_error: 0.111544\n",
      "[440]\ttraining's multi_error: 0.0477042\tvalid_1's multi_error: 0.111572\n",
      "[441]\ttraining's multi_error: 0.0475903\tvalid_1's multi_error: 0.111606\n",
      "[442]\ttraining's multi_error: 0.0475278\tvalid_1's multi_error: 0.111611\n",
      "[443]\ttraining's multi_error: 0.0474264\tvalid_1's multi_error: 0.111583\n",
      "[444]\ttraining's multi_error: 0.0473236\tvalid_1's multi_error: 0.111572\n",
      "[445]\ttraining's multi_error: 0.0472181\tvalid_1's multi_error: 0.111494\n",
      "[446]\ttraining's multi_error: 0.0470653\tvalid_1's multi_error: 0.111567\n",
      "[447]\ttraining's multi_error: 0.0469431\tvalid_1's multi_error: 0.111611\n",
      "[448]\ttraining's multi_error: 0.0468014\tvalid_1's multi_error: 0.111561\n",
      "[449]\ttraining's multi_error: 0.0466486\tvalid_1's multi_error: 0.111483\n",
      "[450]\ttraining's multi_error: 0.0464778\tvalid_1's multi_error: 0.111567\n",
      "[451]\ttraining's multi_error: 0.0464097\tvalid_1's multi_error: 0.111561\n",
      "[452]\ttraining's multi_error: 0.0462569\tvalid_1's multi_error: 0.111539\n",
      "[453]\ttraining's multi_error: 0.0461222\tvalid_1's multi_error: 0.111544\n",
      "[454]\ttraining's multi_error: 0.0460042\tvalid_1's multi_error: 0.111617\n",
      "[455]\ttraining's multi_error: 0.0458569\tvalid_1's multi_error: 0.111639\n",
      "[456]\ttraining's multi_error: 0.0457417\tvalid_1's multi_error: 0.11165\n",
      "[457]\ttraining's multi_error: 0.0456069\tvalid_1's multi_error: 0.111611\n",
      "[458]\ttraining's multi_error: 0.0455028\tvalid_1's multi_error: 0.111572\n",
      "[459]\ttraining's multi_error: 0.0454028\tvalid_1's multi_error: 0.111544\n",
      "[460]\ttraining's multi_error: 0.0452986\tvalid_1's multi_error: 0.111506\n",
      "[461]\ttraining's multi_error: 0.0451736\tvalid_1's multi_error: 0.1115\n",
      "[462]\ttraining's multi_error: 0.0450597\tvalid_1's multi_error: 0.111483\n",
      "[463]\ttraining's multi_error: 0.0448944\tvalid_1's multi_error: 0.111483\n",
      "[464]\ttraining's multi_error: 0.0448153\tvalid_1's multi_error: 0.111472\n",
      "[465]\ttraining's multi_error: 0.0447014\tvalid_1's multi_error: 0.111406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[466]\ttraining's multi_error: 0.0445708\tvalid_1's multi_error: 0.111417\n",
      "[467]\ttraining's multi_error: 0.0444403\tvalid_1's multi_error: 0.111461\n",
      "[468]\ttraining's multi_error: 0.0443292\tvalid_1's multi_error: 0.111367\n",
      "[469]\ttraining's multi_error: 0.0441847\tvalid_1's multi_error: 0.111433\n",
      "[470]\ttraining's multi_error: 0.0440431\tvalid_1's multi_error: 0.111422\n",
      "[471]\ttraining's multi_error: 0.0439264\tvalid_1's multi_error: 0.111417\n",
      "[472]\ttraining's multi_error: 0.0437861\tvalid_1's multi_error: 0.111367\n",
      "[473]\ttraining's multi_error: 0.0437194\tvalid_1's multi_error: 0.111406\n",
      "[474]\ttraining's multi_error: 0.0436236\tvalid_1's multi_error: 0.111411\n",
      "[475]\ttraining's multi_error: 0.0435014\tvalid_1's multi_error: 0.1114\n",
      "[476]\ttraining's multi_error: 0.0433931\tvalid_1's multi_error: 0.111433\n",
      "[477]\ttraining's multi_error: 0.043225\tvalid_1's multi_error: 0.111328\n",
      "[478]\ttraining's multi_error: 0.0431403\tvalid_1's multi_error: 0.111361\n",
      "[479]\ttraining's multi_error: 0.0430194\tvalid_1's multi_error: 0.111278\n",
      "[480]\ttraining's multi_error: 0.0428875\tvalid_1's multi_error: 0.111311\n",
      "[481]\ttraining's multi_error: 0.0427514\tvalid_1's multi_error: 0.111317\n",
      "[482]\ttraining's multi_error: 0.0426042\tvalid_1's multi_error: 0.111367\n",
      "[483]\ttraining's multi_error: 0.0424708\tvalid_1's multi_error: 0.111333\n",
      "[484]\ttraining's multi_error: 0.0423833\tvalid_1's multi_error: 0.111306\n",
      "[485]\ttraining's multi_error: 0.0422569\tvalid_1's multi_error: 0.111428\n",
      "[486]\ttraining's multi_error: 0.0421597\tvalid_1's multi_error: 0.11135\n",
      "[487]\ttraining's multi_error: 0.0420458\tvalid_1's multi_error: 0.111383\n",
      "[488]\ttraining's multi_error: 0.0419722\tvalid_1's multi_error: 0.111383\n",
      "[489]\ttraining's multi_error: 0.0418486\tvalid_1's multi_error: 0.111333\n",
      "[490]\ttraining's multi_error: 0.0417861\tvalid_1's multi_error: 0.111294\n",
      "[491]\ttraining's multi_error: 0.0416778\tvalid_1's multi_error: 0.111328\n",
      "[492]\ttraining's multi_error: 0.0415917\tvalid_1's multi_error: 0.111333\n",
      "[493]\ttraining's multi_error: 0.0414917\tvalid_1's multi_error: 0.111344\n",
      "[494]\ttraining's multi_error: 0.0413875\tvalid_1's multi_error: 0.1113\n",
      "[495]\ttraining's multi_error: 0.0412958\tvalid_1's multi_error: 0.111222\n",
      "[496]\ttraining's multi_error: 0.0411431\tvalid_1's multi_error: 0.111217\n",
      "[497]\ttraining's multi_error: 0.0410208\tvalid_1's multi_error: 0.111217\n",
      "[498]\ttraining's multi_error: 0.0408653\tvalid_1's multi_error: 0.111261\n",
      "[499]\ttraining's multi_error: 0.0407556\tvalid_1's multi_error: 0.111322\n",
      "[500]\ttraining's multi_error: 0.0406764\tvalid_1's multi_error: 0.111283\n",
      "[501]\ttraining's multi_error: 0.0405194\tvalid_1's multi_error: 0.1114\n",
      "[502]\ttraining's multi_error: 0.0403792\tvalid_1's multi_error: 0.111317\n",
      "[503]\ttraining's multi_error: 0.0402972\tvalid_1's multi_error: 0.111289\n",
      "[504]\ttraining's multi_error: 0.0401597\tvalid_1's multi_error: 0.111339\n",
      "[505]\ttraining's multi_error: 0.0400444\tvalid_1's multi_error: 0.111333\n",
      "[506]\ttraining's multi_error: 0.0399306\tvalid_1's multi_error: 0.111283\n",
      "[507]\ttraining's multi_error: 0.0398514\tvalid_1's multi_error: 0.111278\n",
      "[508]\ttraining's multi_error: 0.0397278\tvalid_1's multi_error: 0.11125\n",
      "[509]\ttraining's multi_error: 0.0395917\tvalid_1's multi_error: 0.111272\n",
      "[510]\ttraining's multi_error: 0.0395319\tvalid_1's multi_error: 0.111211\n",
      "[511]\ttraining's multi_error: 0.0394181\tvalid_1's multi_error: 0.111256\n",
      "[512]\ttraining's multi_error: 0.0393444\tvalid_1's multi_error: 0.111289\n",
      "[513]\ttraining's multi_error: 0.0392042\tvalid_1's multi_error: 0.111289\n",
      "[514]\ttraining's multi_error: 0.0390389\tvalid_1's multi_error: 0.111317\n",
      "[515]\ttraining's multi_error: 0.0389556\tvalid_1's multi_error: 0.111339\n",
      "[516]\ttraining's multi_error: 0.0388181\tvalid_1's multi_error: 0.111278\n",
      "[517]\ttraining's multi_error: 0.0387111\tvalid_1's multi_error: 0.111289\n",
      "[518]\ttraining's multi_error: 0.0385861\tvalid_1's multi_error: 0.111306\n",
      "[519]\ttraining's multi_error: 0.0384556\tvalid_1's multi_error: 0.111283\n",
      "[520]\ttraining's multi_error: 0.0382944\tvalid_1's multi_error: 0.11125\n",
      "[521]\ttraining's multi_error: 0.0382139\tvalid_1's multi_error: 0.111272\n",
      "[522]\ttraining's multi_error: 0.0381236\tvalid_1's multi_error: 0.111322\n",
      "[523]\ttraining's multi_error: 0.038\tvalid_1's multi_error: 0.111389\n",
      "[524]\ttraining's multi_error: 0.0379181\tvalid_1's multi_error: 0.111394\n",
      "[525]\ttraining's multi_error: 0.0378222\tvalid_1's multi_error: 0.111428\n",
      "[526]\ttraining's multi_error: 0.0377111\tvalid_1's multi_error: 0.111422\n",
      "[527]\ttraining's multi_error: 0.0376194\tvalid_1's multi_error: 0.111417\n",
      "[528]\ttraining's multi_error: 0.0375194\tvalid_1's multi_error: 0.111422\n",
      "[529]\ttraining's multi_error: 0.0374167\tvalid_1's multi_error: 0.111417\n",
      "[530]\ttraining's multi_error: 0.0372847\tvalid_1's multi_error: 0.111428\n",
      "[531]\ttraining's multi_error: 0.0371764\tvalid_1's multi_error: 0.111389\n",
      "[532]\ttraining's multi_error: 0.0370583\tvalid_1's multi_error: 0.1114\n",
      "[533]\ttraining's multi_error: 0.0369764\tvalid_1's multi_error: 0.111411\n",
      "[534]\ttraining's multi_error: 0.0368903\tvalid_1's multi_error: 0.111428\n",
      "[535]\ttraining's multi_error: 0.036775\tvalid_1's multi_error: 0.111433\n",
      "[536]\ttraining's multi_error: 0.0366569\tvalid_1's multi_error: 0.111417\n",
      "[537]\ttraining's multi_error: 0.0365292\tvalid_1's multi_error: 0.111406\n",
      "[538]\ttraining's multi_error: 0.0364083\tvalid_1's multi_error: 0.111428\n",
      "[539]\ttraining's multi_error: 0.0363208\tvalid_1's multi_error: 0.111428\n",
      "[540]\ttraining's multi_error: 0.0362333\tvalid_1's multi_error: 0.111478\n",
      "[541]\ttraining's multi_error: 0.0361611\tvalid_1's multi_error: 0.111539\n",
      "[542]\ttraining's multi_error: 0.0359972\tvalid_1's multi_error: 0.111478\n",
      "[543]\ttraining's multi_error: 0.0359236\tvalid_1's multi_error: 0.111506\n",
      "[544]\ttraining's multi_error: 0.0358278\tvalid_1's multi_error: 0.111544\n",
      "[545]\ttraining's multi_error: 0.0357361\tvalid_1's multi_error: 0.111439\n",
      "[546]\ttraining's multi_error: 0.0356292\tvalid_1's multi_error: 0.111428\n",
      "[547]\ttraining's multi_error: 0.0355236\tvalid_1's multi_error: 0.111411\n",
      "[548]\ttraining's multi_error: 0.0353861\tvalid_1's multi_error: 0.111439\n",
      "[549]\ttraining's multi_error: 0.0352722\tvalid_1's multi_error: 0.111422\n",
      "[550]\ttraining's multi_error: 0.0351861\tvalid_1's multi_error: 0.111406\n",
      "[551]\ttraining's multi_error: 0.0350889\tvalid_1's multi_error: 0.111394\n",
      "[552]\ttraining's multi_error: 0.0350111\tvalid_1's multi_error: 0.111489\n",
      "[553]\ttraining's multi_error: 0.0348958\tvalid_1's multi_error: 0.111483\n",
      "[554]\ttraining's multi_error: 0.0347653\tvalid_1's multi_error: 0.111489\n",
      "[555]\ttraining's multi_error: 0.0346792\tvalid_1's multi_error: 0.111428\n",
      "[556]\ttraining's multi_error: 0.0345486\tvalid_1's multi_error: 0.111411\n",
      "[557]\ttraining's multi_error: 0.0344181\tvalid_1's multi_error: 0.111433\n",
      "[558]\ttraining's multi_error: 0.0343139\tvalid_1's multi_error: 0.111483\n",
      "[559]\ttraining's multi_error: 0.0342736\tvalid_1's multi_error: 0.11145\n",
      "[560]\ttraining's multi_error: 0.0341528\tvalid_1's multi_error: 0.11145\n",
      "Early stopping, best iteration is:\n",
      "[510]\ttraining's multi_error: 0.0395319\tvalid_1's multi_error: 0.111211\n",
      "Feature importances: [1743, 2062, 3156, 3444, 3066, 2108, 3835, 4813, 3724, 2716, 2707, 3124, 2630, 2360, 3329, 2301, 2743, 3093, 5096, 2620, 4546, 3482, 2470, 2974, 3383, 4085, 4324, 3382, 4582, 2695, 3573, 2682, 3176, 2741, 2596, 2417, 2545, 3483, 2729, 3155, 3837, 3241, 2982, 3908, 3253, 2755, 4257, 3131, 2502, 3976, 2856, 5097, 3471, 3039, 3677, 3669, 2504, 2350, 2839, 3522, 2270, 3910, 2946, 3263, 2459, 3197, 2957, 2588, 3508, 2695, 3611, 2334, 2450, 3419, 2982, 2774, 3185, 3150, 3515, 2595, 3134, 4602]\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'softmax',\n",
    "    'num_class':2,\n",
    "    'metric': 'multi_error',\n",
    "    'num_leaves': 256,\n",
    "    'learning_rate': 0.1,\n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_fraction': 0.7,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 1\n",
    "}\n",
    "print('Starting training...')\n",
    "# train\n",
    "\n",
    "gbm = lgb.train(params,\n",
    "                train_data,\n",
    "                valid_sets=[train_data,eval_data],\n",
    "                num_boost_round = 2000,\n",
    "                early_stopping_rounds=50\n",
    "               )\n",
    "                #early_stopping_rounds=5)\n",
    "gbm.save_model('gender_emb.txt')\n",
    "print('Feature importances:', list(gbm.feature_importance()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " ...\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]]\n",
      "(720000, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import  OneHotEncoder\n",
    "\n",
    "before_one_hot =  y_train.values.reshape([-1,1])\n",
    "print(before_one_hot)\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(before_one_hot)\n",
    "\n",
    "one_hoted_y  = enc.transform(before_one_hot).toarray()\n",
    "print(one_hoted_y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " ...\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]]\n",
      "[[0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " ...\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9604680555555556"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = gbm.predict(X_train)\n",
    "for i in range(len(y_pred)):\n",
    "        max_value=max(y_pred[i])\n",
    "        for j in range(len(y_pred[i])):\n",
    "            if max_value==y_pred[i][j]:\n",
    "                y_pred[i][j]=1\n",
    "            else:\n",
    "                y_pred[i][j]=0\n",
    "print(y_pred)\n",
    "print(one_hoted_y)\n",
    "classification_report(one_hoted_y, y_pred)\n",
    "precision_score(one_hoted_y, y_pred,average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [0.]\n",
      " [1.]\n",
      " ...\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "(180000, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import  OneHotEncoder\n",
    "\n",
    "before_one_hot =  y_test.values.reshape([-1,1])\n",
    "print(before_one_hot)\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(before_one_hot)\n",
    "\n",
    "one_hoted_y  = enc.transform(before_one_hot).toarray()\n",
    "print(one_hoted_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " ...\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n",
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " ...\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8887888888888889"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = gbm.predict(X_test)\n",
    "for i in range(len(y_pred)):\n",
    "        max_value=max(y_pred[i])\n",
    "        for j in range(len(y_pred[i])):\n",
    "            if max_value==y_pred[i][j]:\n",
    "                y_pred[i][j]=1\n",
    "            else:\n",
    "                y_pred[i][j]=0\n",
    "print(y_pred)\n",
    "print(one_hoted_y)\n",
    "classification_report(one_hoted_y, y_pred)\n",
    "precision_score(one_hoted_y, y_pred,average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
