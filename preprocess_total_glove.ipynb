{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import gc\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from gensim.corpora import WikiCorpus\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.word2vec import LineSentence\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from  collections import Counter\n",
    "from mittens import GloVe\n",
    "\n",
    "\n",
    "np.random.seed(2019)\n",
    "random.seed(2019)\n",
    "pd.set_option('display.max_rows', 6)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 280)\n",
    "pd.set_option('display.max_colwidth', 150)\n",
    "data_path = '/data/workspace/kimi/tencent_ads/2020/dataset'\n",
    "preprocess_path = 'preprocess'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          time   user_id  creative_id  click_times      ad_id  product_id  product_category  advertiser_id  industry\n",
      "0          9.0   30920.0     567330.0          1.0   504423.0     30673.0               3.0        32638.0     319.0\n",
      "1         15.0  320815.0     567330.0          1.0   504423.0     30673.0               3.0        32638.0     319.0\n",
      "2         11.0  355089.0     567330.0          1.0   504423.0     30673.0               3.0        32638.0     319.0\n",
      "...        ...       ...          ...          ...        ...         ...               ...            ...       ...\n",
      "30082768  76.0  309198.0    3686554.0          2.0  3172440.0      3979.0               2.0        52506.0     247.0\n",
      "30082769  50.0  309198.0    2386973.0          1.0  2057811.0      1946.0               2.0        17757.0     259.0\n",
      "30082770  12.0   30920.0     717026.0          1.0   634512.0        -1.0              18.0        26466.0     126.0\n",
      "\n",
      "[30082771 rows x 9 columns]\n",
      "          time  user_id  creative_id  click_times   ad_id  product_id  product_category  advertiser_id  industry\n",
      "0           20  3131989       645764            1  573314          58                 2          14689         6\n",
      "1           10  3142948       645764            1  573314          58                 2          14689         6\n",
      "2           14  3170643       645764            1  573314          58                 2          14689         6\n",
      "...        ...      ...          ...          ...     ...         ...               ...            ...       ...\n",
      "33585509     5  3131984       322785            1  290114        2031                 2          19976       238\n",
      "33585510    16  3131984       900585            1  793805        1766                 2          33097       319\n",
      "33585511    16  3131988       899450            1  792851          -1                18          22897        47\n",
      "\n",
      "[33585512 rows x 9 columns]\n",
      "          time    user_id  creative_id  click_times      ad_id  product_id  product_category  advertiser_id  industry\n",
      "2134125    1.0  3969503.0     146454.0          1.0   131508.0        -1.0              18.0        34137.0      40.0\n",
      "25196907   1.0     2267.0     249047.0          1.0   223979.0      1927.0               2.0        15784.0     322.0\n",
      "13936212   1.0   512898.0     168451.0          1.0   150988.0      1243.0               2.0        29966.0     322.0\n",
      "...        ...        ...          ...          ...        ...         ...               ...            ...       ...\n",
      "28730719  91.0  3773900.0    3680751.0          1.0  3167517.0     42718.0              17.0        10259.0      -1.0\n",
      "23168403  91.0   498277.0    3877769.0          1.0  3331468.0     26858.0               3.0           23.0      60.0\n",
      "13125865  91.0   141441.0    4329985.0          1.0  3712996.0     39503.0              17.0        13328.0      -1.0\n",
      "\n",
      "[63668283 rows x 9 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_merged_log(flag):\n",
    "    merged= f'{flag}_merged_log.pkl'\n",
    "    merged_path = f'{preprocess_path}/{merged}'\n",
    "    merged_df = pd.read_pickle(merged_path)\n",
    "    print(merged_df)\n",
    "    return merged_df\n",
    "train_merged_log_df = get_merged_log('train')\n",
    "test_merged_log_df = get_merged_log('test')\n",
    "total_merged_df = pd.concat([train_merged_log_df,test_merged_log_df]).sort_values(by='time')\n",
    "print(total_merged_df)\n",
    "\n",
    "del train_merged_log_df\n",
    "del test_merged_log_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countCOOC(cooccurrence, window, coreIndex,vocab_dic):\n",
    "   # cooccurrence：当前共现矩阵\n",
    "   # window：当前移动窗口数组\n",
    "   # coreIndex：当前移动窗口数组中的窗口中心位置\n",
    "   for index in range(len(window)):\n",
    "       if index == coreIndex:\n",
    "           continue\n",
    "       else:\n",
    "           cooccurrence[vocab_dic[window[coreIndex]]][vocab_dic[window[index]]] = cooccurrence[vocab_dic[window[coreIndex]]][vocab_dic[window[index]]] + 1\n",
    "   return cooccurrence\n",
    "\n",
    "def get_cooccurrence(sentences,vocab_size,vocab_dic,window=10,varbose=1):\n",
    "    cooccurrence = np.zeros((vocab_size, vocab_size), \"int64\" )\n",
    "    flag = 0\n",
    "    for sentence in sentences:\n",
    "       #itemInt = [int(x) for x in sentence]\n",
    "       for center_index in range(1, len(sentence)):\n",
    "           if center_index <= window + 1:\n",
    "               # 左窗口不足\n",
    "               curr_window = sentence[1:core + coWindow + 1]\n",
    "               center_list_index = center_index - 1\n",
    "               cooccurrence = countCOOC(cooccurrence, curr_window, center_list_index,vocab_dic)\n",
    "           elif center_index >= len(item) - 1 - window:\n",
    "               # 右窗口不足\n",
    "               curr_window = sentence[center_index - window:(len(sentence))]\n",
    "               center_list_index = window\n",
    "               cooccurrence = countCOOC(cooccurrence, curr_window, center_list_index,vocab_dic)\n",
    "           else:\n",
    "               # 左右均没有问题\n",
    "               curr_window = sentence[center_index - window:center_index + window + 1]\n",
    "               center_list_index = window\n",
    "               cooccurrence = countCOOC(cooccurrence, curr_window, center_list_index,vocab_dic)\n",
    "       flag = flag + 1\n",
    "       if flag % 1000 == 0 and varbose >=1 :\n",
    "           endTime = datetime.datetime.now()\n",
    "           print(\"已经计算了%s条数据，用时%s\" % (flag, endTime - startTime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def glove(log,pivot,f,flag,L,model_path,seq_len=200,sentence_len=100,window=5):\n",
    "    #word2vec算法\n",
    "    #log为曝光日志，以pivot为主键，f为embedding的对象，flag为dev或test，L是embedding的维度\n",
    "    print(\"glove:\",pivot,f,model_path)\n",
    "    #构造文档\n",
    "    vocab_size=  log[f].nunique() + 1\n",
    "    print(f'vocab_size:{vocab_size}')\n",
    "    vocab = log[f].unique()\n",
    "\n",
    "    word_index = {\" \": 0} # 初始化 `[word : token]` ，后期 tokenize 语料库就是用该词典。使用前必须添加一个索引0.\n",
    "    vocab_dic = {} # 初始化`[word : vector]`字典\n",
    "    for i in range(len(vocab)):\n",
    "        word = vocab[i]  # 每个词语\n",
    "        vocab_dic[word] = i + 1 # 词语：索引\n",
    "\n",
    "    sentence=[]\n",
    "    dic={}\n",
    "    day=0\n",
    "    log['day'] = log['time']\n",
    "    print('build...')\n",
    "    for item in tqdm(log[['day',pivot,f]].values,total=len(log)):\n",
    "        try:\n",
    "            dic[item[1]].append(str(int(item[2])))\n",
    "        except:\n",
    "            dic[item[1]]=[str(int(item[2]))]\n",
    "    \n",
    "    for key in dic:\n",
    "        sentence.append(dic[key])\n",
    "    print(sentence[:5])\n",
    "    print(len(sentence))\n",
    "    #训练Word2Vec模型\n",
    "    print('shuffle...')\n",
    "    random.shuffle(sentence)\n",
    "    \n",
    "    print('cooccurrence ...')\n",
    "    cooccurrence = get_cooccurrence(sentence,vocab_size,vocab_dic)\n",
    "    print('training...')\n",
    "    model = GloVe(n=L, max_iter=1000)\n",
    "    print(model)\n",
    "    emb = model.fit(cooccurrence)\n",
    "    model.save(model_path+f'_{L}')\n",
    "    emb.save(model_path+f'np_{L}')\n",
    "    print(model)\n",
    "    print(emb)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glove: user_id ad_id /data/workspace/kimi/tencent_ads/2020/kimi/model/ad_id_glove.model\n",
      "3027361\n",
      "build...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4530bceb8ecc4391915f1a044b699a1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=63668283), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = 'ad_id'\n",
    "time_seq_df =  glove(total_merged_df,'user_id',f,'total',64,f'/data/workspace/kimi/tencent_ads/2020/kimi/model/{f}_glove.model',600,500,10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#industy_seq_df =  w2v(total_merged_df,'user_id','industry','total',64,'/data/workspace/kimi/tencent_ads/2020/kimi/model/industry_emb.model',600,500,10)\n",
    "#industy_seq_df.to_pickle(industy_seq_path)\n",
    "#print(industy_seq_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#product_id_seq_df = w2v(total_merged_df,'user_id','product_id','total',64,'/data/workspace/kimi/tencent_ads/2020/kimi/model/product_id_emb.model',500,500,10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#advertiser_id_seq_df = w2v(total_merged_df,'user_id','advertiser_id','total',64,'/data/workspace/kimi/tencent_ads/2020/kimi/model/advertiser_id_emb.model',400,500,10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ad_id_seq_df = w2v(total_merged_df,'user_id','ad_id','total',64,'/data/workspace/kimi/tencent_ads/2020/kimi/model/ad_id_emb.model',400,500,10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creative_id_seq_df = w2v(total_merged_df,'user_id','creative_id','total',64,'/data/workspace/kimi/tencent_ads/2020/kimi/model/creative_id_emb.model',400,500,10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
