{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import gc\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from gensim.corpora import WikiCorpus\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.word2vec import LineSentence\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from  collections import Counter\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.preprocessing import  OneHotEncoder\n",
    "\n",
    "np.random.seed(2019)\n",
    "random.seed(2019)\n",
    "pd.set_option('display.max_rows', 6)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 280)\n",
    "pd.set_option('display.max_colwidth', 150)\n",
    "data_path = '/data/workspace/kimi/tencent_ads/2020/dataset'\n",
    "preprocess_path = 'preprocess'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           user_id                                                                                                                                              ad_id_seq\n",
      "0        3969503.0  [131508, 24135, 179398, 212955, 298663, 18413, 82996, 121567, 581344, 222576, 410358, 27028, 102071, 74685, 1215844, 241849, 273087, 1437928, 1187...\n",
      "1           2267.0  [223979, 139563, 79026, 220199, 220126, 274249, 190996, 461148, 50437, 274189, 220199, 533051, 163703, 107932, 113724, 761306, 192657, 624676, 355...\n",
      "2         512898.0  [150988, 133836, 150708, 246310, 250548, 306943, 320970, 204541, 87899, 107984, 147107, 140319, 569029, 598774, 290696, 683618, 690876, 170732, 53...\n",
      "...            ...                                                                                                                                                    ...\n",
      "1899997   742408.0                  [2619335, 3771589, 3332913, 3574432, 73976, 3114229, 3712996, 2495986, 3553252, 1900218, 1757244, 3770207, 2305828, 3724445, 3782579]\n",
      "1899998  3083446.0                                                                      [1727254, 3482289, 3624668, 3350001, 3765613, 3224183, 3645522, 3779639, 3338447]\n",
      "1899999   362414.0                                     [3237379, 1913315, 1160587, 100245, 3096916, 3097620, 108860, 3530521, 2885725, 3759743, 634173, 3203594, 2466702]\n",
      "\n",
      "[1900000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "seq_df = pd.read_pickle(f'{preprocess_path}/ad_id_s64_total_seq.pkl')\n",
    "print(seq_df)\n",
    "seq_df = seq_df[seq_df.user_id < 1000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df = pd.read_csv(f'{data_path}/train_preliminary/user.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df = seq_df.merge(label_df,on='user_id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=3027360, size=64, alpha=0.025)\n",
      "(3027361, 64)\n"
     ]
    }
   ],
   "source": [
    "L = 64\n",
    "emb_model = Word2Vec.load(f'model/ad_id_emb.model_{L}')\n",
    "print(emb_model)\n",
    "import numpy as np\n",
    "\n",
    "vocab_list = [word for word, Vocab in emb_model.wv.vocab.items()]# 存储 所有的 词语\n",
    "\n",
    "word_index = {\" \": 0} # 初始化 `[word : token]` ，后期 tokenize 语料库就是用该词典。使用前必须添加一个索引0.\n",
    "word_vector = {} # 初始化`[word : vector]`字典\n",
    "\n",
    "# 初始化存储所有向量的大矩阵，留意其中多一位（首行），词向量全为 0，用于 padding补零。\n",
    "# 行数 为 所有单词数+1 比如 10000+1 ； 列数为 词向量“维度”比如100。\n",
    "embedding_matrix = np.zeros((len(vocab_list) + 1, emb_model.vector_size))\n",
    "\n",
    "for i in range(len(vocab_list)):\n",
    "    # print(i)\n",
    "    word = vocab_list[i]  # 每个词语\n",
    "    word_index[word] = i + 1 # 词语：索引\n",
    "    word_vector[word] = emb_model.wv[word] # 词语：词向量\n",
    "    embedding_matrix[i + 1] = emb_model.wv[word]  # 词向量矩阵\n",
    "\n",
    "print(embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 900000/900000 [00:13<00:00, 64527.47it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit:900000, miss:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "result=[]\n",
    "hit=0\n",
    "miss=0\n",
    "for row in tqdm(total_df[['user_id','ad_id_seq']].values,total=len(total_df)):\n",
    "    try:\n",
    "        result.append([row[0],[word_index[i]  for i in row[-1]]])\n",
    "        hit+=1\n",
    "    except Exception as e:\n",
    "        miss+=1\n",
    "print(f'hit:{hit}, miss:{miss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         user_id                                                                                                                                          ad_id_int_seq\n",
      "0         2267.0  [963199, 160403, 15881, 756, 25382, 2139, 538883, 451419, 1762, 18246, 756, 818, 1660, 778, 5227, 93053, 27087, 156191, 27605, 33824, 9285, 131681...\n",
      "1       512898.0  [3705, 17415, 1040366, 8680, 1613864, 33623, 342527, 1721, 9515, 109048, 42791, 11593, 327098, 235459, 71953, 129075, 158673, 133890, 1412, 7534, ...\n",
      "2       524600.0  [3705, 27941, 399706, 1921899, 41307, 229487, 781793, 2982853, 294179, 200446, 1365907, 133279, 1670198, 316202, 394748, 252916, 147678, 787520, 1...\n",
      "...          ...                                                                                                                                                    ...\n",
      "899997  868400.0  [67812, 6596, 205148, 368418, 126497, 453053, 9884, 467138, 4554, 1507178, 2629819, 2629820, 499751, 458486, 11287, 32854, 1545551, 133384, 829748...\n",
      "899998  742408.0                                           [11293, 298343, 427743, 34852, 133156, 174456, 38680, 3073, 15494, 242253, 402, 67762, 8971, 323196, 937738]\n",
      "899999  362414.0                                                  [45345, 242364, 4554, 44601, 284788, 395849, 126369, 616405, 1200207, 2420963, 232219, 541746, 15703]\n",
      "\n",
      "[900000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "int_seq_df  = pd.DataFrame(result,columns=['user_id','ad_id_int_seq'])\n",
    "print(int_seq_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(720000, 10)\n",
      "[[2]\n",
      " [2]\n",
      " [1]\n",
      " ...\n",
      " [8]\n",
      " [3]\n",
      " [5]]\n",
      "(180000, 10)\n",
      "[list([963199, 160403, 15881, 756, 25382, 2139, 538883, 451419, 1762, 18246, 756, 818, 1660, 778, 5227, 93053, 27087, 156191, 27605, 33824, 9285, 1316811, 225255, 137354, 552160, 281245, 96585, 2201, 230862, 156191, 2960, 492332, 82325, 80036, 1721, 13393, 40049, 34958, 1976, 29917, 934457, 24271, 43293, 185382, 24875, 43293, 44587, 1597, 32644, 5227, 40064, 185386, 594320, 1371, 1721, 706, 200155, 27136, 96298, 377005, 432345, 726759, 1787, 286213, 30439, 2192, 17901, 25364, 93950, 2289, 242597, 115605, 1330945, 929, 561383, 38752, 8671, 2673052, 90385, 77576, 1024120, 42258, 67706, 9607, 349027, 925104, 192834])\n",
      " list([3705, 17415, 1040366, 8680, 1613864, 33623, 342527, 1721, 9515, 109048, 42791, 11593, 327098, 235459, 71953, 129075, 158673, 133890, 1412, 7534, 349649, 425, 1276905, 1082840, 3087, 1691, 454208, 2015, 354169, 16630, 201620, 1606882, 11593, 46545, 231389, 40048, 421264, 9902, 2929, 784, 2630, 7547, 48298, 302165, 784, 23473, 309805, 2325933, 752678, 1743695, 1202, 2453915, 3878, 5239, 18234, 73346, 2613, 636, 2453916])\n",
      " list([3705, 27941, 399706, 1921899, 41307, 229487, 781793, 2982853, 294179, 200446, 1365907, 133279, 1670198, 316202, 394748, 252916, 147678, 787520, 11572, 2456341, 1427305, 1784194, 9742, 547, 21292, 138324, 27605, 26454, 52825, 1729506, 547, 1319, 1409430, 841108, 2630, 49648, 35515, 14564, 635715, 13465, 27029, 17606, 706, 2893525, 7078, 44955, 2181, 2181, 35039, 1009, 2212, 6583, 307918, 169, 502043, 44601, 3075, 170, 1318, 638, 24167, 287553, 300783, 38678, 1341, 1198, 3069, 111455, 137627, 639792])\n",
      " ...\n",
      " list([928, 7349, 293, 18599, 482906, 13291, 599388, 732349, 2580, 923, 161882, 11800, 5906, 4637, 945, 45771, 908, 6546, 7640])\n",
      " list([89946, 1583665, 10280, 146019, 49405, 1542509, 89946, 126754, 302211])\n",
      " list([45345, 242364, 4554, 44601, 284788, 395849, 126369, 616405, 1200207, 2420963, 232219, 541746, 15703])]\n",
      "720000\n",
      "[[      0       0       0 ...  349027  925104  192834]\n",
      " [      0       0       0 ...    2613     636 2453916]\n",
      " [      0       0       0 ...  111455  137627  639792]\n",
      " ...\n",
      " [      0       0       0 ...     908    6546    7640]\n",
      " [      0       0       0 ...   89946  126754  302211]\n",
      " [      0       0       0 ...  232219  541746   15703]]\n"
     ]
    }
   ],
   "source": [
    "train_df  = int_seq_df[int_seq_df.user_id <=720000]\n",
    "valid_df = int_seq_df[int_seq_df.user_id > 720000]\n",
    "\n",
    "train_df = train_df.merge(label_df,on='user_id',how='left')\n",
    "train_df['age'] =train_df['age'] -1\n",
    "\n",
    "valid_df = valid_df.merge(label_df,on='user_id',how='left')\n",
    "valid_df['age'] =valid_df['age'] -1\n",
    "\n",
    "\n",
    "train_x = np.array(train_df[['ad_id_int_seq']].values[:,0])\n",
    "train_y = train_df[['age']].values\n",
    "\n",
    "valid_x = np.array(valid_df[['ad_id_int_seq']].values[:,0])\n",
    "valid_y = valid_df[['age']].values\n",
    "\n",
    "before_one_hot =  train_y.reshape([-1,1])\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(before_one_hot)\n",
    "\n",
    "one_hoted_train_y  = enc.transform(before_one_hot).toarray()\n",
    "print(one_hoted_train_y.shape)\n",
    "\n",
    "before_one_hot =  valid_y.reshape([-1,1])\n",
    "print(before_one_hot)\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(before_one_hot)\n",
    "\n",
    "one_hoted_valid_y  = enc.transform(before_one_hot).toarray()\n",
    "print(one_hoted_valid_y.shape)\n",
    "\n",
    "print(train_x)\n",
    "print(len(train_x))\n",
    "maxlen = 1000\n",
    "train_x = keras.preprocessing.sequence.pad_sequences(train_x, maxlen=maxlen)\n",
    "valid_x = keras.preprocessing.sequence.pad_sequences(valid_x, maxlen=maxlen)\n",
    "print(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embedding_layer = Embedding(\n",
    "    len(vocab_list) +1,\n",
    "    emb_model.vector_size,\n",
    "    embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
    "    trainable=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, None, 64)          193751104 \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, None, 128)         66048     \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 193,917,258\n",
      "Trainable params: 166,154\n",
      "Non-trainable params: 193,751,104\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "inputs = keras.Input(shape=(None,), dtype=\"int32\")\n",
    "# Embed each integer in a 128-dimensional vector\n",
    "x = embedding_layer(inputs)\n",
    "# Add 2 bidirectional LSTMs\n",
    "x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x)\n",
    "x = layers.Bidirectional(layers.LSTM(64))(x)\n",
    "# Add a classifier\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(720000, 1000)\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(180000, 1000)\n",
      "[[0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Epoch 1/3\n",
      " 3958/22500 [====>.........................] - ETA: 3:19:42 - loss: 1.5664 - accuracy: 0.3567"
     ]
    }
   ],
   "source": [
    "print(train_x.shape)\n",
    "print(one_hoted_train_y)\n",
    "print(valid_x.shape)\n",
    "print(one_hoted_valid_y)\n",
    "\n",
    "model.fit(train_x,one_hoted_train_y, validation_data=(valid_x,one_hoted_valid_y), epochs=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
