{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import gc\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import  OneHotEncoder\n",
    "\n",
    "np.random.seed(2019)\n",
    "random.seed(2019)\n",
    "pd.set_option('display.max_rows', 6)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 280)\n",
    "pd.set_option('display.max_colwidth', 150)\n",
    "data_path = '/data/workspace/kimi/tencent_ads/2020/dataset'\n",
    "preprocess_path = 'preprocess'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         user_id  total_clks  active_days  day_clks_max  day_clks_min  day_clks_mean  day_clks_std  week_clks_max  week_clks_min  week_clks_mean  week_clks_std  weekend_clks_max  weekend_clks_min  weekend_clks_mean  weekend_clks_std  workday_clks_max  workday_clks_min  \\\n",
      "0            1.0        14.0         10.0           3.0           1.0       1.300000      0.674949            3.0            1.0        2.166667       0.983192               2.0               1.0               1.50          0.707107               3.0               1.0   \n",
      "1            2.0        46.0         28.0           4.0           1.0       1.607143      0.994030            7.0            1.0        4.090909       2.256304               1.0               1.0               1.00          0.000000               7.0               1.0   \n",
      "2            3.0        30.0         23.0           3.0           1.0       1.304348      0.634950            6.0            1.0        3.000000       1.763834               2.0               1.0               1.25          0.500000               5.0               1.0   \n",
      "...          ...         ...          ...           ...           ...            ...           ...            ...            ...             ...            ...               ...               ...                ...               ...               ...               ...   \n",
      "838468  899998.0        15.0         10.0           3.0           1.0       1.400000      0.699206            7.0            1.0        2.333333       2.338090               3.0               1.0               2.00          1.414214               4.0               1.0   \n",
      "838469  899999.0        22.0         17.0           2.0           1.0       1.294118      0.469668            4.0            1.0        2.444444       1.130388               2.0               2.0               2.00          0.000000               4.0               1.0   \n",
      "838470  900000.0        12.0         12.0           1.0           1.0       1.000000      0.000000            2.0            1.0        1.333333       0.500000               1.0               1.0               1.00          0.000000               2.0               1.0   \n",
      "\n",
      "        workday_clks_mean  workday_clks_std  month_clks_max  month_clks_min  month_clks_mean  month_clks_std  age  gender  \n",
      "0                1.666667          0.816497             5.0             3.0         4.333333        1.154701  3.0     1.0  \n",
      "1                4.300000          2.057507            21.0             1.0        11.250000        8.958236  9.0     1.0  \n",
      "2                2.500000          1.509231            12.0             8.0        10.000000        2.000000  6.0     2.0  \n",
      "...                   ...               ...             ...             ...              ...             ...  ...     ...  \n",
      "838468           2.000000          1.224745             9.0             1.0         3.500000        3.785939  3.0     2.0  \n",
      "838469           2.222222          1.201850             9.0             5.0         7.333333        2.081666  2.0     1.0  \n",
      "838470           1.250000          0.462910             4.0             1.0         3.000000        1.414214  2.0     2.0  \n",
      "\n",
      "[838471 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "train_df =pd.read_pickle(f'{preprocess_path}/train_user.pkl')\n",
    "label_df = pd.read_csv(f'{data_path}/train_preliminary/user.csv')\n",
    "train_df = train_df.merge(label_df,on='user_id')\n",
    "train_df['age'] = train_df['age'] -1\n",
    "train_df = train_df.astype(float)\n",
    "print(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         3\n",
      "1         9\n",
      "2         6\n",
      "         ..\n",
      "838468    3\n",
      "838469    2\n",
      "838470    2\n",
      "Name: age, Length: 838471, dtype: int64\n",
      "(670776, 22)\n"
     ]
    }
   ],
   "source": [
    "x = train_df.drop(['age','user_id','gender',], axis=1)\n",
    "y = train_df['age'].astype(int)\n",
    "print(x)\n",
    "print(y)\n",
    "\n",
    "train_x,valid_x,train_y,valid_y =  train_test_split(x,y,test_size=0.20, random_state=42)\n",
    "print(train_x.shape)\n",
    "train_data = lgb.Dataset(train_x.values, label=train_y, feature_name=list(train_x.columns),free_raw_data=False)\n",
    "valid_data = lgb.Dataset(valid_x.values, label=valid_y, feature_name=list(train_x.columns),free_raw_data=False,reference=train_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[1]\ttraining's multi_error: 0.775163\tvalid_1's multi_error: 0.773977\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[2]\ttraining's multi_error: 0.775156\tvalid_1's multi_error: 0.773977\n",
      "[3]\ttraining's multi_error: 0.775154\tvalid_1's multi_error: 0.773977\n",
      "[4]\ttraining's multi_error: 0.775098\tvalid_1's multi_error: 0.773988\n",
      "[5]\ttraining's multi_error: 0.775043\tvalid_1's multi_error: 0.773988\n",
      "[6]\ttraining's multi_error: 0.774949\tvalid_1's multi_error: 0.773994\n",
      "[7]\ttraining's multi_error: 0.774804\tvalid_1's multi_error: 0.773983\n",
      "[8]\ttraining's multi_error: 0.774642\tvalid_1's multi_error: 0.773977\n",
      "[9]\ttraining's multi_error: 0.774402\tvalid_1's multi_error: 0.773887\n",
      "[10]\ttraining's multi_error: 0.774154\tvalid_1's multi_error: 0.773839\n",
      "[11]\ttraining's multi_error: 0.773886\tvalid_1's multi_error: 0.773822\n",
      "[12]\ttraining's multi_error: 0.773608\tvalid_1's multi_error: 0.77381\n",
      "[13]\ttraining's multi_error: 0.773252\tvalid_1's multi_error: 0.773774\n",
      "[14]\ttraining's multi_error: 0.77286\tvalid_1's multi_error: 0.773774\n",
      "[15]\ttraining's multi_error: 0.772434\tvalid_1's multi_error: 0.773744\n",
      "[16]\ttraining's multi_error: 0.772162\tvalid_1's multi_error: 0.773744\n",
      "[17]\ttraining's multi_error: 0.77183\tvalid_1's multi_error: 0.773738\n",
      "[18]\ttraining's multi_error: 0.771415\tvalid_1's multi_error: 0.773666\n",
      "[19]\ttraining's multi_error: 0.771095\tvalid_1's multi_error: 0.773708\n",
      "[20]\ttraining's multi_error: 0.770819\tvalid_1's multi_error: 0.773696\n",
      "[21]\ttraining's multi_error: 0.770499\tvalid_1's multi_error: 0.773696\n",
      "[22]\ttraining's multi_error: 0.770048\tvalid_1's multi_error: 0.773768\n",
      "[23]\ttraining's multi_error: 0.769779\tvalid_1's multi_error: 0.773935\n",
      "[24]\ttraining's multi_error: 0.769352\tvalid_1's multi_error: 0.773947\n",
      "[25]\ttraining's multi_error: 0.768935\tvalid_1's multi_error: 0.773839\n",
      "[26]\ttraining's multi_error: 0.768534\tvalid_1's multi_error: 0.773911\n",
      "[27]\ttraining's multi_error: 0.768142\tvalid_1's multi_error: 0.773899\n",
      "[28]\ttraining's multi_error: 0.767849\tvalid_1's multi_error: 0.773953\n",
      "[29]\ttraining's multi_error: 0.76753\tvalid_1's multi_error: 0.773941\n",
      "[30]\ttraining's multi_error: 0.767188\tvalid_1's multi_error: 0.774006\n",
      "[31]\ttraining's multi_error: 0.766742\tvalid_1's multi_error: 0.773988\n",
      "[32]\ttraining's multi_error: 0.766396\tvalid_1's multi_error: 0.773983\n",
      "[33]\ttraining's multi_error: 0.766035\tvalid_1's multi_error: 0.774078\n",
      "[34]\ttraining's multi_error: 0.765628\tvalid_1's multi_error: 0.774036\n",
      "[35]\ttraining's multi_error: 0.765273\tvalid_1's multi_error: 0.774048\n",
      "[36]\ttraining's multi_error: 0.764999\tvalid_1's multi_error: 0.774084\n",
      "[37]\ttraining's multi_error: 0.764676\tvalid_1's multi_error: 0.774132\n",
      "[38]\ttraining's multi_error: 0.76427\tvalid_1's multi_error: 0.77412\n",
      "[39]\ttraining's multi_error: 0.763944\tvalid_1's multi_error: 0.774126\n",
      "[40]\ttraining's multi_error: 0.763529\tvalid_1's multi_error: 0.77409\n",
      "[41]\ttraining's multi_error: 0.763164\tvalid_1's multi_error: 0.774024\n",
      "[42]\ttraining's multi_error: 0.762664\tvalid_1's multi_error: 0.774126\n",
      "[43]\ttraining's multi_error: 0.762314\tvalid_1's multi_error: 0.774102\n",
      "[44]\ttraining's multi_error: 0.76184\tvalid_1's multi_error: 0.774042\n",
      "[45]\ttraining's multi_error: 0.761385\tvalid_1's multi_error: 0.774006\n",
      "[46]\ttraining's multi_error: 0.760993\tvalid_1's multi_error: 0.774006\n",
      "[47]\ttraining's multi_error: 0.76078\tvalid_1's multi_error: 0.774054\n",
      "[48]\ttraining's multi_error: 0.760482\tvalid_1's multi_error: 0.774084\n",
      "[49]\ttraining's multi_error: 0.760272\tvalid_1's multi_error: 0.774203\n",
      "[50]\ttraining's multi_error: 0.759977\tvalid_1's multi_error: 0.774191\n",
      "[51]\ttraining's multi_error: 0.759537\tvalid_1's multi_error: 0.774358\n",
      "[52]\ttraining's multi_error: 0.759247\tvalid_1's multi_error: 0.774388\n",
      "[53]\ttraining's multi_error: 0.758908\tvalid_1's multi_error: 0.774394\n",
      "[54]\ttraining's multi_error: 0.758422\tvalid_1's multi_error: 0.77446\n",
      "[55]\ttraining's multi_error: 0.758056\tvalid_1's multi_error: 0.77437\n",
      "[56]\ttraining's multi_error: 0.757657\tvalid_1's multi_error: 0.774376\n",
      "[57]\ttraining's multi_error: 0.757298\tvalid_1's multi_error: 0.774328\n",
      "[58]\ttraining's multi_error: 0.757059\tvalid_1's multi_error: 0.774364\n",
      "[59]\ttraining's multi_error: 0.756659\tvalid_1's multi_error: 0.774501\n",
      "[60]\ttraining's multi_error: 0.756302\tvalid_1's multi_error: 0.774483\n",
      "[61]\ttraining's multi_error: 0.756009\tvalid_1's multi_error: 0.774638\n",
      "[62]\ttraining's multi_error: 0.755673\tvalid_1's multi_error: 0.77471\n",
      "[63]\ttraining's multi_error: 0.755482\tvalid_1's multi_error: 0.774698\n",
      "[64]\ttraining's multi_error: 0.755133\tvalid_1's multi_error: 0.774704\n",
      "[65]\ttraining's multi_error: 0.754787\tvalid_1's multi_error: 0.774698\n",
      "[66]\ttraining's multi_error: 0.754463\tvalid_1's multi_error: 0.774746\n",
      "[67]\ttraining's multi_error: 0.75415\tvalid_1's multi_error: 0.774686\n",
      "[68]\ttraining's multi_error: 0.753836\tvalid_1's multi_error: 0.774811\n",
      "[69]\ttraining's multi_error: 0.753547\tvalid_1's multi_error: 0.774895\n",
      "[70]\ttraining's multi_error: 0.753177\tvalid_1's multi_error: 0.774913\n",
      "[71]\ttraining's multi_error: 0.753074\tvalid_1's multi_error: 0.774919\n",
      "[72]\ttraining's multi_error: 0.752757\tvalid_1's multi_error: 0.774877\n",
      "[73]\ttraining's multi_error: 0.7526\tvalid_1's multi_error: 0.774978\n",
      "[74]\ttraining's multi_error: 0.752352\tvalid_1's multi_error: 0.774847\n",
      "[75]\ttraining's multi_error: 0.751941\tvalid_1's multi_error: 0.774794\n",
      "[76]\ttraining's multi_error: 0.75158\tvalid_1's multi_error: 0.774847\n",
      "[77]\ttraining's multi_error: 0.751173\tvalid_1's multi_error: 0.774794\n",
      "[78]\ttraining's multi_error: 0.750844\tvalid_1's multi_error: 0.774805\n",
      "[79]\ttraining's multi_error: 0.75055\tvalid_1's multi_error: 0.774704\n",
      "[80]\ttraining's multi_error: 0.750244\tvalid_1's multi_error: 0.774698\n",
      "[81]\ttraining's multi_error: 0.749855\tvalid_1's multi_error: 0.774633\n",
      "[82]\ttraining's multi_error: 0.749581\tvalid_1's multi_error: 0.774704\n",
      "[83]\ttraining's multi_error: 0.749101\tvalid_1's multi_error: 0.774698\n",
      "[84]\ttraining's multi_error: 0.74873\tvalid_1's multi_error: 0.774728\n",
      "[85]\ttraining's multi_error: 0.748314\tvalid_1's multi_error: 0.774823\n",
      "[86]\ttraining's multi_error: 0.748029\tvalid_1's multi_error: 0.774799\n",
      "[87]\ttraining's multi_error: 0.747643\tvalid_1's multi_error: 0.774889\n",
      "[88]\ttraining's multi_error: 0.747291\tvalid_1's multi_error: 0.774949\n",
      "[89]\ttraining's multi_error: 0.746823\tvalid_1's multi_error: 0.774943\n",
      "[90]\ttraining's multi_error: 0.7464\tvalid_1's multi_error: 0.774949\n",
      "[91]\ttraining's multi_error: 0.746225\tvalid_1's multi_error: 0.77505\n",
      "[92]\ttraining's multi_error: 0.745957\tvalid_1's multi_error: 0.775002\n",
      "[93]\ttraining's multi_error: 0.745762\tvalid_1's multi_error: 0.774937\n",
      "[94]\ttraining's multi_error: 0.745537\tvalid_1's multi_error: 0.774847\n",
      "[95]\ttraining's multi_error: 0.74527\tvalid_1's multi_error: 0.774919\n",
      "[96]\ttraining's multi_error: 0.744897\tvalid_1's multi_error: 0.774966\n",
      "[97]\ttraining's multi_error: 0.744526\tvalid_1's multi_error: 0.775074\n",
      "[98]\ttraining's multi_error: 0.744113\tvalid_1's multi_error: 0.774984\n",
      "[99]\ttraining's multi_error: 0.743749\tvalid_1's multi_error: 0.774913\n",
      "[100]\ttraining's multi_error: 0.743409\tvalid_1's multi_error: 0.774996\n",
      "[101]\ttraining's multi_error: 0.743056\tvalid_1's multi_error: 0.774889\n",
      "[102]\ttraining's multi_error: 0.74258\tvalid_1's multi_error: 0.774835\n",
      "[103]\ttraining's multi_error: 0.742222\tvalid_1's multi_error: 0.77499\n",
      "[104]\ttraining's multi_error: 0.741777\tvalid_1's multi_error: 0.775014\n",
      "[105]\ttraining's multi_error: 0.741329\tvalid_1's multi_error: 0.775056\n",
      "[106]\ttraining's multi_error: 0.74104\tvalid_1's multi_error: 0.775014\n",
      "[107]\ttraining's multi_error: 0.740653\tvalid_1's multi_error: 0.775133\n",
      "[108]\ttraining's multi_error: 0.740316\tvalid_1's multi_error: 0.775163\n",
      "[109]\ttraining's multi_error: 0.739906\tvalid_1's multi_error: 0.775116\n",
      "[110]\ttraining's multi_error: 0.739745\tvalid_1's multi_error: 0.775133\n",
      "[111]\ttraining's multi_error: 0.739461\tvalid_1's multi_error: 0.77505\n",
      "[112]\ttraining's multi_error: 0.739181\tvalid_1's multi_error: 0.775127\n",
      "[113]\ttraining's multi_error: 0.73888\tvalid_1's multi_error: 0.775086\n",
      "[114]\ttraining's multi_error: 0.738542\tvalid_1's multi_error: 0.775098\n",
      "[115]\ttraining's multi_error: 0.738187\tvalid_1's multi_error: 0.775038\n",
      "[116]\ttraining's multi_error: 0.737798\tvalid_1's multi_error: 0.775187\n",
      "[117]\ttraining's multi_error: 0.737324\tvalid_1's multi_error: 0.775199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[118]\ttraining's multi_error: 0.737031\tvalid_1's multi_error: 0.775259\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's multi_error: 0.771415\tvalid_1's multi_error: 0.773666\n",
      "Feature importances: [1564, 1304, 448, 6, 1947, 1642, 611, 207, 1403, 1885, 289, 113, 1041, 1123, 564, 182, 1567, 1776, 1092, 771, 1530, 1795]\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'softmax',\n",
    "    'num_class':10,\n",
    "    'metric': 'multi_error',\n",
    "    'num_leaves': 128,\n",
    "    'learning_rate': 0.1,\n",
    "    'feature_fraction': 0.7,\n",
    "    'bagging_fraction': 0.7,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 1\n",
    "}\n",
    "print('Starting training...')\n",
    "# train\n",
    "\n",
    "gbm = lgb.train(params,\n",
    "                train_data,\n",
    "                 valid_sets=[train_data,valid_data],\n",
    "                num_boost_round = 2000,\n",
    "                early_stopping_rounds=100\n",
    "               )\n",
    "gbm.save_model('age_emb1.txt')\n",
    "print('Feature importances:', list(gbm.feature_importance()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_one_hot =  final_train_y_df.values.reshape([-1,1])\n",
    "print(before_one_hot)\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(before_one_hot)\n",
    "\n",
    "one_hoted_y  = enc.transform(before_one_hot).toarray()\n",
    "print(one_hoted_y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gbm.predict(final_train_x_df)\n",
    "for i in range(len(y_pred)):\n",
    "        max_value=max(y_pred[i])\n",
    "        for j in range(len(y_pred[i])):\n",
    "            if max_value==y_pred[i][j]:\n",
    "                y_pred[i][j]=1\n",
    "            else:\n",
    "                y_pred[i][j]=0\n",
    "                \n",
    "print(precision_score(one_hoted_y, y_pred,average='micro'))\n",
    "\n",
    "ret = []\n",
    "for user_id,age in zip(range(1000000),y_pred):\n",
    "    ret.append([int(user_id),int(age.tolist().index(1) + 1)])\n",
    "ret_df = pd.DataFrame(ret,columns=['user_id','predicted_age'])\n",
    "print(ret_df['predicted_age'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "before_one_hot =  final_valid_y_df.values.reshape([-1,1])\n",
    "print(before_one_hot)\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(before_one_hot)\n",
    "\n",
    "one_hoted_y  = enc.transform(before_one_hot).toarray()\n",
    "print(one_hoted_y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gbm.predict(final_valid_x_df)\n",
    "for i in range(len(y_pred)):\n",
    "        max_value=max(y_pred[i])\n",
    "        for j in range(len(y_pred[i])):\n",
    "            if max_value==y_pred[i][j]:\n",
    "                y_pred[i][j]=1\n",
    "            else:\n",
    "                y_pred[i][j]=0\n",
    "                \n",
    "precision_score(one_hoted_y, y_pred,average='micro')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = []\n",
    "for user_id,age in zip(range(1000000),y_pred):\n",
    "    ret.append([int(user_id),int(age.tolist().index(1) + 1)])\n",
    "ret_df = pd.DataFrame(ret,columns=['user_id','predicted_age'])\n",
    "print(ret_df['predicted_age'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
