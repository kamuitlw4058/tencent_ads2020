{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import gc\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(2019)\n",
    "random.seed(2019)\n",
    "pd.set_option('display.max_rows', 20)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 280)\n",
    "pd.set_option('display.max_colwidth', 150)\n",
    "data_path = '/data/workspace/kimi/tencent_ads/2020/dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df =pd.read_pickle('train1.pkl')\n",
    "train_df.replace(\"\\\\N\",-1,inplace=True)\n",
    "train_df=train_df.astype(float,inplace=True)\n",
    "train_df['age']  = train_df['age'] -1\n",
    "print(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train_x_df = train_df.drop(['age','user_id','gender'], axis=1)\n",
    "#final_train_x_df = train_df.drop(['age','user_id','gender','active_days'], axis=1)\n",
    "final_train_y_df = train_df['age']\n",
    "X_train, X_test, y_train, y_test = train_test_split(final_train_x_df, final_train_y_df, test_size=0.20, random_state=42)\n",
    "#train_data_show_df =train_df.drop(['active_days', 'click_times_total','max_clicked_industry_cnt','clicked_industry','clicked_advertiser','max_clicked_advertiser_cnt','max_clicked_industry_ratio','max_clicked_advertiser_ratio'], axis=1)\n",
    "#print(X_train)\n",
    "num_normal_features = ['_clicks_max_click_cnt','_max_clicked_ratio','_clicks_min_click_cnt','_min_clicked_ratio','_clicks_len','_clicks_mean','_clicks_median','_clicks_std']\n",
    "num_date_features  = [ '_clicks_max_click_cnt', '_clicks_min_click_cnt','_clicks_len','_clicks_mean','_clicks_median','_clicks_std']\n",
    "num_features = ['click_times_total'] +\\\n",
    "                [f'date{i}'  for i in num_date_features] + \\\n",
    "                [f'wday{i}'  for i in num_date_features] + \\\n",
    "                [f'month{i}'  for i in num_date_features] + \\\n",
    "                 [f'product_id{i}'  for i in num_normal_features] + \\\n",
    "                 [f'product_category{i}'  for i in num_normal_features] + \\\n",
    "                [f'industry{i}'  for i in num_normal_features] + \\\n",
    "                [f'advertiser_id{i}'  for i in num_normal_features]\n",
    "\n",
    "#print(num_features)\n",
    "\n",
    "c_features = ['industry_clicks_max_click','industry_clicks_min_click',\n",
    "              'advertiser_id_clicks_max_click','advertiser_id_clicks_min_click',\n",
    "              'product_id_clicks_max_click','product_id_clicks_min_click',\n",
    "              'product_category_clicks_max_click','product_category_clicks_min_click',\n",
    "             ]\n",
    "features= num_features + c_features\n",
    "features= [f\"tfidf_{i}\" for i in range(317)] +['active_days','click_times_total']\n",
    "#train_data = lgb.Dataset(final_train_x_df, label=final_train_y_df, feature_name=[   'max_clicked_industry', 'max_clicked_advertiser_id' ], categorical_feature=['max_clicked_industry','max_clicked_advertiser_id'])\n",
    "#train_data = lgb.Dataset(X_train, label=y_train, feature_name=features, categorical_feature=c_features,free_raw_data=False)\n",
    "train_data = lgb.Dataset(X_train, label=y_train, feature_name=features,free_raw_data=False)\n",
    "\n",
    "eval_data = lgb.Dataset(X_test, label=y_test, feature_name=features, categorical_feature=c_features,free_raw_data=False,reference=train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[1]\ttraining's multi_error: 0.774357\tvalid_1's multi_error: 0.774978\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[2]\ttraining's multi_error: 0.774125\tvalid_1's multi_error: 0.774861\n",
      "[3]\ttraining's multi_error: 0.772618\tvalid_1's multi_error: 0.773894\n",
      "[4]\ttraining's multi_error: 0.768843\tvalid_1's multi_error: 0.771444\n",
      "[5]\ttraining's multi_error: 0.763867\tvalid_1's multi_error: 0.768667\n",
      "[6]\ttraining's multi_error: 0.758508\tvalid_1's multi_error: 0.765206\n",
      "[7]\ttraining's multi_error: 0.751949\tvalid_1's multi_error: 0.761106\n",
      "[8]\ttraining's multi_error: 0.744914\tvalid_1's multi_error: 0.756494\n",
      "[9]\ttraining's multi_error: 0.738356\tvalid_1's multi_error: 0.751972\n",
      "[10]\ttraining's multi_error: 0.732706\tvalid_1's multi_error: 0.7488\n",
      "[11]\ttraining's multi_error: 0.726985\tvalid_1's multi_error: 0.745194\n",
      "[12]\ttraining's multi_error: 0.72175\tvalid_1's multi_error: 0.742317\n",
      "[13]\ttraining's multi_error: 0.717508\tvalid_1's multi_error: 0.7402\n",
      "[14]\ttraining's multi_error: 0.713525\tvalid_1's multi_error: 0.737783\n",
      "[15]\ttraining's multi_error: 0.710063\tvalid_1's multi_error: 0.736211\n",
      "[16]\ttraining's multi_error: 0.706565\tvalid_1's multi_error: 0.734567\n",
      "[17]\ttraining's multi_error: 0.703368\tvalid_1's multi_error: 0.732961\n",
      "[18]\ttraining's multi_error: 0.700314\tvalid_1's multi_error: 0.731667\n",
      "[19]\ttraining's multi_error: 0.697719\tvalid_1's multi_error: 0.730411\n",
      "[20]\ttraining's multi_error: 0.695081\tvalid_1's multi_error: 0.729178\n",
      "[21]\ttraining's multi_error: 0.692758\tvalid_1's multi_error: 0.728011\n",
      "[22]\ttraining's multi_error: 0.690253\tvalid_1's multi_error: 0.726928\n",
      "[23]\ttraining's multi_error: 0.688114\tvalid_1's multi_error: 0.726522\n",
      "[24]\ttraining's multi_error: 0.685886\tvalid_1's multi_error: 0.725933\n",
      "[25]\ttraining's multi_error: 0.683885\tvalid_1's multi_error: 0.725006\n",
      "[26]\ttraining's multi_error: 0.681921\tvalid_1's multi_error: 0.724128\n",
      "[27]\ttraining's multi_error: 0.679739\tvalid_1's multi_error: 0.723056\n",
      "[28]\ttraining's multi_error: 0.677899\tvalid_1's multi_error: 0.722539\n",
      "[29]\ttraining's multi_error: 0.675957\tvalid_1's multi_error: 0.722056\n",
      "[30]\ttraining's multi_error: 0.673886\tvalid_1's multi_error: 0.721478\n",
      "[31]\ttraining's multi_error: 0.672085\tvalid_1's multi_error: 0.721167\n",
      "[32]\ttraining's multi_error: 0.670347\tvalid_1's multi_error: 0.720544\n",
      "[33]\ttraining's multi_error: 0.668526\tvalid_1's multi_error: 0.720178\n",
      "[34]\ttraining's multi_error: 0.667015\tvalid_1's multi_error: 0.719783\n",
      "[35]\ttraining's multi_error: 0.665432\tvalid_1's multi_error: 0.719217\n",
      "[36]\ttraining's multi_error: 0.663604\tvalid_1's multi_error: 0.718917\n",
      "[37]\ttraining's multi_error: 0.661915\tvalid_1's multi_error: 0.7186\n",
      "[38]\ttraining's multi_error: 0.660279\tvalid_1's multi_error: 0.718183\n",
      "[39]\ttraining's multi_error: 0.658789\tvalid_1's multi_error: 0.718022\n",
      "[40]\ttraining's multi_error: 0.657419\tvalid_1's multi_error: 0.717789\n",
      "[41]\ttraining's multi_error: 0.655833\tvalid_1's multi_error: 0.717522\n",
      "[42]\ttraining's multi_error: 0.654112\tvalid_1's multi_error: 0.717461\n",
      "[43]\ttraining's multi_error: 0.652679\tvalid_1's multi_error: 0.717411\n",
      "[44]\ttraining's multi_error: 0.651049\tvalid_1's multi_error: 0.717111\n",
      "[45]\ttraining's multi_error: 0.649789\tvalid_1's multi_error: 0.717067\n",
      "[46]\ttraining's multi_error: 0.6484\tvalid_1's multi_error: 0.716472\n",
      "[47]\ttraining's multi_error: 0.647157\tvalid_1's multi_error: 0.71635\n",
      "[48]\ttraining's multi_error: 0.645799\tvalid_1's multi_error: 0.715733\n",
      "[49]\ttraining's multi_error: 0.644479\tvalid_1's multi_error: 0.7155\n",
      "[50]\ttraining's multi_error: 0.643096\tvalid_1's multi_error: 0.715422\n",
      "[51]\ttraining's multi_error: 0.641715\tvalid_1's multi_error: 0.715517\n",
      "[52]\ttraining's multi_error: 0.640564\tvalid_1's multi_error: 0.715044\n",
      "[53]\ttraining's multi_error: 0.639365\tvalid_1's multi_error: 0.715111\n",
      "[54]\ttraining's multi_error: 0.638104\tvalid_1's multi_error: 0.714772\n",
      "[55]\ttraining's multi_error: 0.636929\tvalid_1's multi_error: 0.714622\n",
      "[56]\ttraining's multi_error: 0.635681\tvalid_1's multi_error: 0.714156\n",
      "[57]\ttraining's multi_error: 0.634361\tvalid_1's multi_error: 0.714139\n",
      "[58]\ttraining's multi_error: 0.632971\tvalid_1's multi_error: 0.714144\n",
      "[59]\ttraining's multi_error: 0.631828\tvalid_1's multi_error: 0.713678\n",
      "[60]\ttraining's multi_error: 0.630599\tvalid_1's multi_error: 0.713933\n",
      "[61]\ttraining's multi_error: 0.629376\tvalid_1's multi_error: 0.713644\n",
      "[62]\ttraining's multi_error: 0.628126\tvalid_1's multi_error: 0.713644\n",
      "[63]\ttraining's multi_error: 0.626904\tvalid_1's multi_error: 0.713456\n",
      "[64]\ttraining's multi_error: 0.625693\tvalid_1's multi_error: 0.713133\n",
      "[65]\ttraining's multi_error: 0.624424\tvalid_1's multi_error: 0.71295\n",
      "[66]\ttraining's multi_error: 0.62334\tvalid_1's multi_error: 0.712933\n",
      "[67]\ttraining's multi_error: 0.622247\tvalid_1's multi_error: 0.713017\n",
      "[68]\ttraining's multi_error: 0.621026\tvalid_1's multi_error: 0.712939\n",
      "[69]\ttraining's multi_error: 0.619833\tvalid_1's multi_error: 0.713106\n",
      "[70]\ttraining's multi_error: 0.618728\tvalid_1's multi_error: 0.713056\n",
      "[71]\ttraining's multi_error: 0.617518\tvalid_1's multi_error: 0.712794\n",
      "[72]\ttraining's multi_error: 0.616446\tvalid_1's multi_error: 0.71265\n",
      "[73]\ttraining's multi_error: 0.6154\tvalid_1's multi_error: 0.712772\n",
      "[74]\ttraining's multi_error: 0.614446\tvalid_1's multi_error: 0.712439\n",
      "[75]\ttraining's multi_error: 0.61336\tvalid_1's multi_error: 0.712678\n",
      "[76]\ttraining's multi_error: 0.612122\tvalid_1's multi_error: 0.712367\n",
      "[77]\ttraining's multi_error: 0.611038\tvalid_1's multi_error: 0.712728\n",
      "[78]\ttraining's multi_error: 0.60995\tvalid_1's multi_error: 0.712533\n",
      "[79]\ttraining's multi_error: 0.608892\tvalid_1's multi_error: 0.712506\n",
      "[80]\ttraining's multi_error: 0.607928\tvalid_1's multi_error: 0.712278\n",
      "[81]\ttraining's multi_error: 0.606675\tvalid_1's multi_error: 0.712333\n",
      "[82]\ttraining's multi_error: 0.605525\tvalid_1's multi_error: 0.712289\n",
      "[83]\ttraining's multi_error: 0.604328\tvalid_1's multi_error: 0.712433\n",
      "[84]\ttraining's multi_error: 0.603301\tvalid_1's multi_error: 0.712661\n",
      "[85]\ttraining's multi_error: 0.602192\tvalid_1's multi_error: 0.712528\n",
      "[86]\ttraining's multi_error: 0.600972\tvalid_1's multi_error: 0.712689\n",
      "[87]\ttraining's multi_error: 0.599964\tvalid_1's multi_error: 0.712417\n",
      "[88]\ttraining's multi_error: 0.598819\tvalid_1's multi_error: 0.712394\n",
      "[89]\ttraining's multi_error: 0.597829\tvalid_1's multi_error: 0.712156\n",
      "[90]\ttraining's multi_error: 0.596861\tvalid_1's multi_error: 0.712111\n",
      "[91]\ttraining's multi_error: 0.595706\tvalid_1's multi_error: 0.712139\n",
      "[92]\ttraining's multi_error: 0.594665\tvalid_1's multi_error: 0.711894\n",
      "[93]\ttraining's multi_error: 0.593725\tvalid_1's multi_error: 0.711728\n",
      "[94]\ttraining's multi_error: 0.592897\tvalid_1's multi_error: 0.711506\n",
      "[95]\ttraining's multi_error: 0.591885\tvalid_1's multi_error: 0.71175\n",
      "[96]\ttraining's multi_error: 0.590786\tvalid_1's multi_error: 0.711761\n",
      "[97]\ttraining's multi_error: 0.589926\tvalid_1's multi_error: 0.711861\n",
      "[98]\ttraining's multi_error: 0.588986\tvalid_1's multi_error: 0.711839\n",
      "[99]\ttraining's multi_error: 0.58809\tvalid_1's multi_error: 0.711839\n",
      "[100]\ttraining's multi_error: 0.587228\tvalid_1's multi_error: 0.711567\n",
      "[101]\ttraining's multi_error: 0.586143\tvalid_1's multi_error: 0.711944\n",
      "[102]\ttraining's multi_error: 0.585147\tvalid_1's multi_error: 0.711761\n",
      "[103]\ttraining's multi_error: 0.584237\tvalid_1's multi_error: 0.711856\n",
      "[104]\ttraining's multi_error: 0.583332\tvalid_1's multi_error: 0.711772\n",
      "[105]\ttraining's multi_error: 0.582363\tvalid_1's multi_error: 0.711939\n",
      "[106]\ttraining's multi_error: 0.581478\tvalid_1's multi_error: 0.711967\n",
      "[107]\ttraining's multi_error: 0.58061\tvalid_1's multi_error: 0.7115\n",
      "[108]\ttraining's multi_error: 0.57955\tvalid_1's multi_error: 0.711522\n",
      "[109]\ttraining's multi_error: 0.578661\tvalid_1's multi_error: 0.711433\n",
      "[110]\ttraining's multi_error: 0.577725\tvalid_1's multi_error: 0.711628\n",
      "[111]\ttraining's multi_error: 0.576758\tvalid_1's multi_error: 0.71135\n",
      "[112]\ttraining's multi_error: 0.575854\tvalid_1's multi_error: 0.711189\n",
      "[113]\ttraining's multi_error: 0.574997\tvalid_1's multi_error: 0.7115\n",
      "[114]\ttraining's multi_error: 0.574153\tvalid_1's multi_error: 0.711594\n",
      "[115]\ttraining's multi_error: 0.573135\tvalid_1's multi_error: 0.711417\n",
      "[116]\ttraining's multi_error: 0.572117\tvalid_1's multi_error: 0.71145\n",
      "[117]\ttraining's multi_error: 0.571239\tvalid_1's multi_error: 0.711622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[118]\ttraining's multi_error: 0.570304\tvalid_1's multi_error: 0.711756\n",
      "[119]\ttraining's multi_error: 0.569528\tvalid_1's multi_error: 0.711917\n",
      "[120]\ttraining's multi_error: 0.568728\tvalid_1's multi_error: 0.711789\n",
      "[121]\ttraining's multi_error: 0.567656\tvalid_1's multi_error: 0.711656\n",
      "[122]\ttraining's multi_error: 0.56679\tvalid_1's multi_error: 0.711622\n",
      "[123]\ttraining's multi_error: 0.565703\tvalid_1's multi_error: 0.711717\n",
      "[124]\ttraining's multi_error: 0.564672\tvalid_1's multi_error: 0.711778\n",
      "[125]\ttraining's multi_error: 0.563907\tvalid_1's multi_error: 0.711633\n",
      "[126]\ttraining's multi_error: 0.562856\tvalid_1's multi_error: 0.711583\n",
      "[127]\ttraining's multi_error: 0.561967\tvalid_1's multi_error: 0.711533\n",
      "[128]\ttraining's multi_error: 0.560956\tvalid_1's multi_error: 0.711561\n",
      "[129]\ttraining's multi_error: 0.56015\tvalid_1's multi_error: 0.711644\n",
      "[130]\ttraining's multi_error: 0.559265\tvalid_1's multi_error: 0.71175\n",
      "[131]\ttraining's multi_error: 0.558307\tvalid_1's multi_error: 0.7118\n",
      "[132]\ttraining's multi_error: 0.557499\tvalid_1's multi_error: 0.711817\n",
      "[133]\ttraining's multi_error: 0.556776\tvalid_1's multi_error: 0.711883\n",
      "[134]\ttraining's multi_error: 0.555864\tvalid_1's multi_error: 0.712089\n",
      "[135]\ttraining's multi_error: 0.555103\tvalid_1's multi_error: 0.712078\n",
      "[136]\ttraining's multi_error: 0.554283\tvalid_1's multi_error: 0.711989\n",
      "[137]\ttraining's multi_error: 0.553478\tvalid_1's multi_error: 0.711767\n",
      "[138]\ttraining's multi_error: 0.552468\tvalid_1's multi_error: 0.711917\n",
      "[139]\ttraining's multi_error: 0.551704\tvalid_1's multi_error: 0.712222\n",
      "[140]\ttraining's multi_error: 0.550864\tvalid_1's multi_error: 0.712239\n",
      "[141]\ttraining's multi_error: 0.549968\tvalid_1's multi_error: 0.712239\n",
      "[142]\ttraining's multi_error: 0.549199\tvalid_1's multi_error: 0.712183\n",
      "[143]\ttraining's multi_error: 0.548406\tvalid_1's multi_error: 0.712106\n",
      "[144]\ttraining's multi_error: 0.547806\tvalid_1's multi_error: 0.712017\n",
      "[145]\ttraining's multi_error: 0.547057\tvalid_1's multi_error: 0.711844\n",
      "[146]\ttraining's multi_error: 0.546188\tvalid_1's multi_error: 0.711711\n",
      "[147]\ttraining's multi_error: 0.545303\tvalid_1's multi_error: 0.711806\n",
      "[148]\ttraining's multi_error: 0.544651\tvalid_1's multi_error: 0.711706\n",
      "[149]\ttraining's multi_error: 0.543911\tvalid_1's multi_error: 0.711778\n",
      "[150]\ttraining's multi_error: 0.543182\tvalid_1's multi_error: 0.711922\n",
      "[151]\ttraining's multi_error: 0.542393\tvalid_1's multi_error: 0.71195\n",
      "[152]\ttraining's multi_error: 0.541431\tvalid_1's multi_error: 0.711817\n",
      "[153]\ttraining's multi_error: 0.540592\tvalid_1's multi_error: 0.712\n",
      "[154]\ttraining's multi_error: 0.539713\tvalid_1's multi_error: 0.711911\n",
      "[155]\ttraining's multi_error: 0.538808\tvalid_1's multi_error: 0.711789\n",
      "[156]\ttraining's multi_error: 0.538069\tvalid_1's multi_error: 0.711867\n",
      "[157]\ttraining's multi_error: 0.537144\tvalid_1's multi_error: 0.711772\n",
      "[158]\ttraining's multi_error: 0.536351\tvalid_1's multi_error: 0.711833\n",
      "[159]\ttraining's multi_error: 0.535618\tvalid_1's multi_error: 0.711839\n",
      "[160]\ttraining's multi_error: 0.534928\tvalid_1's multi_error: 0.711672\n",
      "[161]\ttraining's multi_error: 0.533951\tvalid_1's multi_error: 0.711789\n",
      "[162]\ttraining's multi_error: 0.533156\tvalid_1's multi_error: 0.711917\n",
      "[163]\ttraining's multi_error: 0.5323\tvalid_1's multi_error: 0.711944\n",
      "[164]\ttraining's multi_error: 0.531493\tvalid_1's multi_error: 0.711861\n",
      "[165]\ttraining's multi_error: 0.530656\tvalid_1's multi_error: 0.711556\n",
      "[166]\ttraining's multi_error: 0.529863\tvalid_1's multi_error: 0.711744\n",
      "[167]\ttraining's multi_error: 0.529167\tvalid_1's multi_error: 0.711789\n",
      "[168]\ttraining's multi_error: 0.528288\tvalid_1's multi_error: 0.712022\n",
      "[169]\ttraining's multi_error: 0.527576\tvalid_1's multi_error: 0.712083\n",
      "[170]\ttraining's multi_error: 0.52691\tvalid_1's multi_error: 0.711922\n",
      "[171]\ttraining's multi_error: 0.526079\tvalid_1's multi_error: 0.711956\n",
      "[172]\ttraining's multi_error: 0.525315\tvalid_1's multi_error: 0.712\n",
      "[173]\ttraining's multi_error: 0.524597\tvalid_1's multi_error: 0.711917\n",
      "[174]\ttraining's multi_error: 0.523758\tvalid_1's multi_error: 0.712094\n",
      "[175]\ttraining's multi_error: 0.52304\tvalid_1's multi_error: 0.712033\n",
      "[176]\ttraining's multi_error: 0.522285\tvalid_1's multi_error: 0.7121\n",
      "[177]\ttraining's multi_error: 0.521492\tvalid_1's multi_error: 0.711961\n",
      "[178]\ttraining's multi_error: 0.520758\tvalid_1's multi_error: 0.711883\n",
      "[179]\ttraining's multi_error: 0.520015\tvalid_1's multi_error: 0.711878\n",
      "[180]\ttraining's multi_error: 0.519246\tvalid_1's multi_error: 0.7118\n",
      "[181]\ttraining's multi_error: 0.518493\tvalid_1's multi_error: 0.71185\n",
      "[182]\ttraining's multi_error: 0.517585\tvalid_1's multi_error: 0.7118\n",
      "[183]\ttraining's multi_error: 0.516856\tvalid_1's multi_error: 0.712061\n",
      "[184]\ttraining's multi_error: 0.516046\tvalid_1's multi_error: 0.712133\n",
      "[185]\ttraining's multi_error: 0.515228\tvalid_1's multi_error: 0.712128\n",
      "[186]\ttraining's multi_error: 0.514447\tvalid_1's multi_error: 0.711939\n",
      "[187]\ttraining's multi_error: 0.513747\tvalid_1's multi_error: 0.7119\n",
      "[188]\ttraining's multi_error: 0.512929\tvalid_1's multi_error: 0.712039\n",
      "[189]\ttraining's multi_error: 0.512176\tvalid_1's multi_error: 0.712022\n",
      "[190]\ttraining's multi_error: 0.511581\tvalid_1's multi_error: 0.711989\n",
      "[191]\ttraining's multi_error: 0.510786\tvalid_1's multi_error: 0.712078\n",
      "[192]\ttraining's multi_error: 0.510096\tvalid_1's multi_error: 0.712083\n",
      "[193]\ttraining's multi_error: 0.509347\tvalid_1's multi_error: 0.712167\n",
      "[194]\ttraining's multi_error: 0.508533\tvalid_1's multi_error: 0.712267\n",
      "[195]\ttraining's multi_error: 0.507876\tvalid_1's multi_error: 0.7122\n",
      "[196]\ttraining's multi_error: 0.507204\tvalid_1's multi_error: 0.712172\n",
      "[197]\ttraining's multi_error: 0.506468\tvalid_1's multi_error: 0.712333\n",
      "[198]\ttraining's multi_error: 0.505828\tvalid_1's multi_error: 0.712228\n",
      "[199]\ttraining's multi_error: 0.505072\tvalid_1's multi_error: 0.712317\n",
      "[200]\ttraining's multi_error: 0.504389\tvalid_1's multi_error: 0.712483\n",
      "[201]\ttraining's multi_error: 0.503676\tvalid_1's multi_error: 0.712467\n",
      "[202]\ttraining's multi_error: 0.503038\tvalid_1's multi_error: 0.712728\n",
      "[203]\ttraining's multi_error: 0.502265\tvalid_1's multi_error: 0.712594\n",
      "[204]\ttraining's multi_error: 0.501614\tvalid_1's multi_error: 0.7126\n",
      "[205]\ttraining's multi_error: 0.500911\tvalid_1's multi_error: 0.712611\n",
      "[206]\ttraining's multi_error: 0.50014\tvalid_1's multi_error: 0.712611\n",
      "[207]\ttraining's multi_error: 0.499468\tvalid_1's multi_error: 0.712494\n",
      "[208]\ttraining's multi_error: 0.498757\tvalid_1's multi_error: 0.712306\n",
      "[209]\ttraining's multi_error: 0.49809\tvalid_1's multi_error: 0.712489\n",
      "[210]\ttraining's multi_error: 0.497428\tvalid_1's multi_error: 0.712589\n",
      "[211]\ttraining's multi_error: 0.496769\tvalid_1's multi_error: 0.712633\n",
      "[212]\ttraining's multi_error: 0.496121\tvalid_1's multi_error: 0.712606\n",
      "Early stopping, best iteration is:\n",
      "[112]\ttraining's multi_error: 0.575854\tvalid_1's multi_error: 0.711189\n",
      "Feature importances: [5888, 6312, 0, 240, 0, 0, 0, 1259, 24, 908, 1130, 541, 1305, 50, 10, 310, 74, 712, 0, 9, 813, 0, 24, 77, 480, 127, 15, 0, 32, 441, 135, 362, 20, 25, 137, 2152, 139, 0, 4, 1353, 685, 548, 147, 887, 875, 20, 0, 6, 278, 0, 0, 45, 0, 429, 2217, 1990, 1398, 5, 0, 25, 0, 1556, 490, 19, 492, 390, 44, 59, 0, 1853, 485, 145, 383, 644, 23, 1287, 515, 0, 3, 43, 365, 315, 832, 301, 201, 1104, 31, 5, 773, 508, 0, 0, 443, 2713, 0, 25, 270, 39, 364, 662, 2, 0, 997, 0, 0, 63, 0, 0, 102, 3488, 395, 3177, 2736, 363, 2112, 90, 2451, 2, 880, 3342, 36, 3, 0, 0, 179, 2420, 1922, 2211, 102, 865, 81, 967, 928, 696, 6, 2, 9, 470, 327, 80, 174, 865, 1783, 2179, 1749, 2557, 384, 312, 1080, 298, 4720, 21, 2755, 634, 457, 5075, 0, 0, 918, 3489, 6601, 3934, 251, 3681, 1673, 1141, 2911, 2779, 919, 1430, 1175, 235, 815, 2617, 2589, 1068, 1963, 908, 291, 4, 5, 0, 0, 0, 0, 2940, 42, 342, 1, 0, 0, 17, 0, 2266, 6, 7, 2245, 0, 47, 0, 0, 0, 0, 460, 0, 2104, 4654, 2332, 827, 3321, 2113, 2019, 208, 1293, 3259, 5255, 611, 278, 134, 2068, 441, 1340, 127, 56, 635, 32, 96, 7, 2, 552, 25, 44, 177, 3, 4, 211, 139, 5771, 3110, 7378, 134, 1819, 2410, 6128, 1025, 18, 0, 4665, 574, 1265, 2795, 0, 461, 114, 23, 1451, 863, 48, 2397, 2045, 3698, 0, 1, 52, 3042, 0, 0, 42, 1530, 320, 3715, 9, 4, 0, 1, 0, 310, 5999, 281, 0, 1495, 775, 0, 4236, 313, 46, 98, 360, 65, 121, 4, 0, 1, 0, 0, 620, 5039, 2002, 154, 7, 0, 0, 995, 1387, 0, 1559, 480, 1507, 1296, 3721, 1396, 64, 0, 0, 0, 0, 0, 1144, 488]\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'softmax',\n",
    "    'num_class':10,\n",
    "    'metric': 'multi_error',\n",
    "    'num_leaves': 256,\n",
    "    'learning_rate': 0.1,\n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_fraction': 0.7,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 1\n",
    "}\n",
    "print('Starting training...')\n",
    "# train\n",
    "\n",
    "gbm = lgb.train(params,\n",
    "                train_data,\n",
    "                valid_sets=[train_data,eval_data],\n",
    "                num_boost_round = 1000,\n",
    "                early_stopping_rounds=100\n",
    "               )\n",
    "                #early_stopping_rounds=5)\n",
    "\n",
    "print('Feature importances:', list(gbm.feature_importance()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.]\n",
      " [1.]\n",
      " [3.]\n",
      " ...\n",
      " [5.]\n",
      " [2.]\n",
      " [6.]]\n",
      "(720000, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import  OneHotEncoder\n",
    "\n",
    "before_one_hot =  y_train.values.reshape([-1,1])\n",
    "print(before_one_hot)\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(before_one_hot)\n",
    "\n",
    "one_hoted_y  = enc.transform(before_one_hot).toarray()\n",
    "print(one_hoted_y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = gbm.predict(X_train)\n",
    "for i in range(len(y_pred)):\n",
    "        max_value=max(y_pred[i])\n",
    "        for j in range(len(y_pred[i])):\n",
    "            if max_value==y_pred[i][j]:\n",
    "                y_pred[i][j]=1\n",
    "            else:\n",
    "                y_pred[i][j]=0\n",
    "print(y_pred)\n",
    "print(one_hoted_y)\n",
    "classification_report(one_hoted_y, y_pred)\n",
    "precision_score(one_hoted_y, y_pred,average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
